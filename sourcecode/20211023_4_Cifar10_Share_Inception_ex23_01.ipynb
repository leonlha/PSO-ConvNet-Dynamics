{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "IBQ_eVTu8OnB",
    "outputId": "a0117324-8e60-4944-c431-14ed244b4f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4497774749050029162\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2815014372747312324\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12984116350975674772\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10747837184\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4617036753611986743\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "LP5lidXD8ViI",
    "outputId": "2ff8199e-96f9-40cd-dd5b-e85cb49178c2"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rYOoAdFk8ma3",
    "outputId": "4e860915-8468-45db-fbcf-be0d20e5c2df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/datastorage/Phong\n"
     ]
    }
   ],
   "source": [
    "cd /media/datastorage/Phong/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "mDdxdcwj8ozr",
    "outputId": "68605cb6-d5ad-42dd-ce42-3e58e2b7b5db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7191252\r\n",
      "drwxrwxr-x 20 bribeiro bribeiro       4096 ago 23  2019 \u001b[0m\u001b[01;34mcassava\u001b[0m/\r\n",
      "drwxrwxr-x  5 bribeiro bribeiro       4096 mar 18  2021 \u001b[01;34mcifar10\u001b[0m/\r\n",
      "drwxrwxr-x 15 bribeiro bribeiro       4096 set  3  2020 \u001b[01;34mcifar100_png\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro  169001437 ago  8  2020 \u001b[01;31mcifar-100-python.tar.gz\u001b[0m\r\n",
      "drwxr-xr-x  2 bribeiro bribeiro       4096 fev  6  2021 \u001b[01;34mdataset5\u001b[0m/\r\n",
      "drwxrwxr-x 15 bribeiro bribeiro       4096 set  3  2019 \u001b[01;34mDogAge\u001b[0m/\r\n",
      "drwxrwxr-x 17 bribeiro bribeiro       4096 ago  8  2020 \u001b[01;34mfashion_mnist\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro 2246539027 fev  4  2021 \u001b[01;31mfingerspelling5.tar.bz2\u001b[0m\r\n",
      "drwxrwxr-x  6 bribeiro bribeiro       4096 ago  5  2019 \u001b[01;34mImageNet\u001b[0m/\r\n",
      "drwxrwxr-x  3 bribeiro bribeiro       4096 fev 24  2021 \u001b[01;34mImageNet2\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro  793579520 out 20  2011 \u001b[01;31mimages.tar\u001b[0m\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro  182349464 set 22  2019 \u001b[01;31mlibcudnn7_7.6.4.38-1+cuda10.1_amd64.deb\u001b[0m\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro  160754004 set 22  2019 \u001b[01;31mlibcudnn7-dev_7.6.4.38-1+cuda10.1_amd64.deb\u001b[0m\r\n",
      "drwxrwxr-x  3 bribeiro bribeiro       4096 mar 20  2019 \u001b[01;34m__MACOSX\u001b[0m/\r\n",
      "drwxrwxr-x 17 bribeiro bribeiro      20480 mar  5  2021 \u001b[01;34mNat19\u001b[0m/\r\n",
      "drwxrwxr-x 21 bribeiro bribeiro       4096 nov 30  2019 \u001b[01;34mNat19_2\u001b[0m/\r\n",
      "-rw-------  1 bribeiro bribeiro          0 set 27  2019 nohup.out\r\n",
      "drwxr-xr-x 40 bribeiro bribeiro       4096 set 23  2018 \u001b[01;34moriginal\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro  881664546 fev 14  2021 \u001b[01;31moriginal_plant_diseases.zip\u001b[0m\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1233422 fev 15  2021 PD_MobileNet_A_L1_1502.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1233359 fev 15  2021 PD_MobileNet_A_L2_1502.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1233366 fev 15  2021 PD_MobileNet_A_L3_1502.csv\r\n",
      "drwxrwxr-x  2 bribeiro bribeiro       4096 fev 15  2021 \u001b[01;34mplant_diseases_data\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro  842382110 fev 13  2021 \u001b[01;31mplant_disease.zip\u001b[0m\r\n",
      "drwxrwxr-x 10 bribeiro bribeiro       4096 fev 17  2021 \u001b[01;34mplantvillage\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1233511 fev 16  2021 plantvillage_1_Ensemble_1602_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1233396 fev 16  2021 plantvillage_1_Ensemble_1602_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1233397 fev 16  2021 plantvillage_1_Ensemble_1602_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1258125 fev 16  2021 plantvillage_2_Ensemble_1602_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1258230 fev 16  2021 plantvillage_2_Ensemble_1602_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1258223 fev 16  2021 plantvillage_2_Ensemble_1602_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1242271 fev 16  2021 plantvillage_3_Ensemble_1602_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1242167 fev 16  2021 plantvillage_3_Ensemble_1602_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1242146 fev 16  2021 plantvillage_3_Ensemble_1602_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1244679 fev 17  2021 plantvillage_4_Ensemble_1602_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1244770 fev 17  2021 plantvillage_4_Ensemble_1602_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1244737 fev 17  2021 plantvillage_4_Ensemble_1602_meana36.csv\r\n",
      "drwxrwxr-x  6 bribeiro bribeiro       4096 jun 22  2020 \u001b[01;34msiim_isic_melanoma\u001b[0m/\r\n",
      "drwxrwxr-x 18 bribeiro bribeiro       4096 ago 31  2019 \u001b[01;34mSTFDG\u001b[0m/\r\n",
      "drwxrwxr-x  7 bribeiro bribeiro       4096 fev  9  2021 \u001b[01;34msurrey\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360577 fev  9  2021 surrey_A_Ensemble_0902_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360577 fev  9  2021 surrey_A_Ensemble_0902_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360577 fev  9  2021 surrey_A_Ensemble_0902_meana34.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360577 fev  9  2021 surrey_A_Ensemble_0902_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378678 fev  9  2021 surrey_AVG_Ensemble_0902_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378678 fev  9  2021 surrey_AVG_Ensemble_0902_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400912 fev  9  2021 surrey_B_Ensemble_0902_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400912 fev  9  2021 surrey_B_Ensemble_0902_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400912 fev  9  2021 surrey_B_Ensemble_0902_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385732 fev  9  2021 surrey_C_Ensemble_0902_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385732 fev  9  2021 surrey_C_Ensemble_0902_meana24.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385732 fev  9  2021 surrey_C_Ensemble_0902_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385732 fev  9  2021 surrey_C_Ensemble_0902_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378678 fev  9  2021 surrey_D_Ensemble_0902_meana26.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378678 fev  9  2021 surrey_D_Ensemble_0902_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_EffNetB1_B_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_EffNetB1_C_L1_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378686 fev  9  2021 Surrey_EffNetB1_D_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360585 fev  9  2021 Surrey_InceptionV3_A_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360585 fev  9  2021 Surrey_InceptionV3_A_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360585 fev  9  2021 Surrey_InceptionV3_A_L3_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_InceptionV3_B_L1_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_InceptionV3_B_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_InceptionV3_B_L3_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_InceptionV3_C_L1_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_InceptionV3_C_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_InceptionV3_C_L3_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378686 fev  9  2021 Surrey_InceptionV3_D_L1_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378686 fev  9  2021 Surrey_InceptionV3_D_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378686 fev  9  2021 Surrey_InceptionV3_D_L3_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360585 fev  9  2021 Surrey_MobileNet_A_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360585 fev  9  2021 Surrey_MobileNet_A_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_MobileNet_B_L1_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_MobileNet_B_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_MobileNet_B_L3_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_MobileNet_C_L1_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_MobileNet_C_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_MobileNet_C_L3_0902.csv\r\n",
      "drwxrwxr-x  7 bribeiro bribeiro       4096 mar  5  2021 \u001b[01;34msurrey_share\u001b[0m/\r\n",
      "drwxrwxr-x  8 bribeiro bribeiro       4096 ago 28  2020 \u001b[01;34msvhn\u001b[0m/\r\n",
      "drwxrwxr-x 20 bribeiro bribeiro      20480 mar  5  2021 \u001b[01;34msvhn_v2\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro         18 mar  5  2021 test1.txt\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro 2054118015 set 27  2019 \u001b[01;31mtest.zip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "313ttIKg8riI",
    "outputId": "32ea2f07-35d7-4504-ce4c-2d7aa40c84bb"
   },
   "outputs": [],
   "source": [
    "# #Images/n02105855-Shetland_sheepdog/n02105855_9415.jpg\n",
    "\n",
    "# import glob\n",
    "# import os\n",
    "\n",
    "# import numpy as np\n",
    "# from matplotlib.image import imread\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # get image parts\n",
    "# def get_image_parts(image_path):\n",
    "#     \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "#     parts = image_path.split(os.path.sep)\n",
    "#     #print(parts)\n",
    "#     filename = parts[2]\n",
    "#     filename_no_ext = filename.split('.')[0]\n",
    "#     classname = parts[1]\n",
    "#     train_or_test = parts[0]\n",
    "    \n",
    "#     return train_or_test, classname, filename_no_ext, filename\n",
    "    \n",
    "    \n",
    "# sample_images = list(glob.glob(os.path.join('train/', '*/*'), recursive=True))\n",
    "# np.random.seed(42)\n",
    "# rand_imgs = np.random.choice(sample_images, size=5*5)\n",
    "# fig, axarr = plt.subplots(5, 5, figsize=(20, 20))\n",
    "\n",
    "# for i, rand_img in enumerate(rand_imgs):\n",
    "#     train_or_test, classname, filename_no_ext, filename = get_image_parts(rand_img)\n",
    "    \n",
    "#     j = i // 5\n",
    "#     k = i % 5\n",
    "#     axarr[j][k].imshow(imread(rand_img))\n",
    "#     axarr[j][k].title.set_text(classname)\n",
    "#     axarr[j][k].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "UOyt3E-j8tJo",
    "outputId": "969c4599-bc6b-46f0-f648-d2cfca0450b0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "#Stop training on val_acc\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "#Save large model using pickle formate instead of h5            \n",
    "class SaveCheckPoint(Callback):\n",
    "    def __init__(self, model, dest_folder):\n",
    "        super(Callback, self).__init__()\n",
    "        self.model = model\n",
    "        self.dest_folder = dest_folder\n",
    "        \n",
    "        #initiate\n",
    "        self.best_val_acc = 0\n",
    "        self.best_val_loss = sys.maxsize #get max value\n",
    "          \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_acc = logs['val_acc']\n",
    "        val_loss = logs['val_loss']\n",
    "\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            \n",
    "            # Save weights in pickle format instead of h5\n",
    "            print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "            weigh= self.model.get_weights()\n",
    "\n",
    "            #now, use pickle to save your model weights, instead of .h5\n",
    "            #for heavy model architectures, .h5 file is unsupported.\n",
    "            fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "            pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "            fpkl.close()\n",
    "            \n",
    "#             model.save('tmp.h5')\n",
    "        elif val_acc == self.best_val_acc:\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss=val_loss\n",
    "                \n",
    "                # Save weights in pickle format instead of h5\n",
    "                print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "                weigh= self.model.get_weights()\n",
    "\n",
    "                #now, use pickle to save your model weights, instead of .h5\n",
    "                #for heavy model architectures, .h5 file is unsupported.\n",
    "                fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "                pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "                fpkl.close()                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUL 1 - Inception - ST\n",
    "\n",
    "from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "# from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, SimpleRNN, LSTM, Flatten, GRU, Reshape\n",
    "\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "# from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def get_adv_model():\n",
    "    f1_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(299,299,3))  \n",
    "    \n",
    "#     #frozen layers    \n",
    "#     for layer in f1_base.layers:\n",
    "#         layer.trainable = False  \n",
    "        \n",
    "    f1_x = f1_base.output\n",
    "    f1_x = GlobalAveragePooling2D()(f1_x)    \n",
    "    \n",
    "#     f1_base = EfficientNetB0(include_top=False, weights='imagenet', \n",
    "#                     input_shape=(299, 299, 3), \n",
    "#                     pooling='avg')\n",
    "#     f1_x = f1_base.output\n",
    "\n",
    "# f1_x = f1_base.layers[-151].output   #layer 5\n",
    "\n",
    "# f1_x = GlobalAveragePooling2D()(f1_x)\n",
    "# f1_x = Flatten()(f1_x)\n",
    "\n",
    "# f1_x = Reshape([1,1280])(f1_x)  \n",
    "# f1_x = SimpleRNN(2048, \n",
    "#             return_sequences=False,                       \n",
    "# #             dropout=0.8                                     \n",
    "#             input_shape=[1,1280])(f1_x)\n",
    "   \n",
    "    #Regularization with noise\n",
    "    f1_x = GaussianNoise(0.1)(f1_x)\n",
    "\n",
    "    f1_x = Dense(1024, activation='relu')(f1_x)\n",
    "    f1_x = Dense(10, activation='softmax')(f1_x)\n",
    "    model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
    "    model_1.summary()\n",
    "    \n",
    "    return model_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1E7n8ds9Mmh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FXZBAIXAElcd",
    "outputId": "0d8aaee3-0db2-4b08-c426-d26e581d2c10"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "19V0B0rIEgso",
    "outputId": "78573b3b-934c-45ae-9c10-ccb28e635e0e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "1JMB1lsREbAE",
    "outputId": "1cad26f1-9c6f-4801-bb78-84f43a11e0c7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "2suPqhuJDOLn",
    "outputId": "d0b80840-ba14-4470-cb33-c850af69491d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "6SqCtLbgSoQ-",
    "outputId": "2a7c1ac8-a9b2-44c2-c368-91125b14a983"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUUPvXA2S7ev"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UsII2atxTYdG",
    "outputId": "a1c0b166-9ed8-4005-faa8-d2932fa8de5a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BL0e6CLIFwxN",
    "outputId": "960af38c-994c-41b2-9f00-a95d1d56ce6c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA1wZ0ODjKlX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7tCxvDxjNU9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgOQh92Ar10r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Dj-itflssqh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwbSVOPnorCq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "cyl_Xjunolpe",
    "outputId": "0ca332e8-f4f4-4903-c7f3-68c5e41ff860"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "zPyjRcTfytFG",
    "outputId": "2de3a5b1-a9f6-4103-fb2b-631c9e505281"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emlc7dUpq9C1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_sKj8LQqr-g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgL7cGRAqy7p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtFSHddZq16W"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGOfqcePBqpH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SjTDA8VC5Ah"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILRxLOABDF7u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "8pDocSJKCtV7",
    "outputId": "a56f8b2d-8684-4f05-e17f-16a84fdd6b3b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WJiLtHmPZ2Ts",
    "outputId": "2e15b430-2dfa-42b8-bc91-6418e714bf62"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "cdFkG0pEacF1",
    "outputId": "6682d252-6c53-4324-a2bf-83d285c6ff27"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41MCKnMGanT1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVSEeQWrbWvn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RM7cE3Skbpw9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "# class CutMixImageDataGenerator():\n",
    "#     def __init__(self, generator1, generator2, img_size, batch_size):\n",
    "#         self.batch_index = 0\n",
    "#         self.samples = generator1.samples\n",
    "#         self.class_indices = generator1.class_indices\n",
    "#         self.generator1 = generator1\n",
    "#         self.generator2 = generator2\n",
    "#         self.img_size = img_size\n",
    "#         self.batch_size = batch_size\n",
    "\n",
    "#     def reset_index(self):  # Ordering Reset (If Shuffle is True, Shuffle Again)\n",
    "#         self.generator1._set_index_array()\n",
    "#         self.generator2._set_index_array()\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.batch_index = 0\n",
    "#         self.generator1.reset()\n",
    "#         self.generator2.reset()\n",
    "#         self.reset_index()\n",
    "\n",
    "#     def get_steps_per_epoch(self):\n",
    "#         quotient, remainder = divmod(self.samples, self.batch_size)\n",
    "#         return (quotient + 1) if remainder else quotient\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         self.get_steps_per_epoch()\n",
    "\n",
    "#     def __next__(self):\n",
    "#         if self.batch_index == 0: self.reset()\n",
    "\n",
    "#         crt_idx = self.batch_index * self.batch_size\n",
    "#         if self.samples > crt_idx + self.batch_size:\n",
    "#             self.batch_index += 1\n",
    "#         else:  # If current index over number of samples\n",
    "#             self.batch_index = 0\n",
    "\n",
    "#         reshape_size = self.batch_size\n",
    "#         last_step_start_idx = (self.get_steps_per_epoch()-1) * self.batch_size\n",
    "#         if crt_idx == last_step_start_idx:\n",
    "#             reshape_size = self.samples - last_step_start_idx\n",
    "            \n",
    "#         X_1, y_1 = self.generator1.next()\n",
    "#         X_2, y_2 = self.generator2.next()\n",
    "        \n",
    "#         cut_ratio = np.random.beta(a=1, b=1, size=reshape_size)\n",
    "#         cut_ratio = np.clip(cut_ratio, 0.2, 0.8)\n",
    "#         label_ratio = cut_ratio.reshape(reshape_size, 1)\n",
    "#         cut_img = X_2\n",
    "\n",
    "#         X = X_1\n",
    "#         for i in range(reshape_size):\n",
    "#             cut_size = int((self.img_size-1) * cut_ratio[i])\n",
    "#             y1 = random.randint(0, (self.img_size-1) - cut_size)\n",
    "#             x1 = random.randint(0, (self.img_size-1) - cut_size)\n",
    "#             y2 = y1 + cut_size\n",
    "#             x2 = x1 + cut_size\n",
    "#             cut_arr = cut_img[i][y1:y2, x1:x2]\n",
    "#             cutmix_img = X_1[i]\n",
    "#             cutmix_img[y1:y2, x1:x2] = cut_arr\n",
    "#             X[i] = cutmix_img\n",
    "            \n",
    "#         # X = seq.augment_images(X)  # Sequential of imgaug\n",
    "#         y = y_1 * (1 - (label_ratio ** 2)) + y_2 * (label_ratio ** 2)\n",
    "#         return X, y\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         while True:\n",
    "#             yield next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "P1hxliT6aR_a",
    "outputId": "a359bc33-6afa-4da1-a5fe-13aab3996ef7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of GPUs: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           10250       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 23,911,210\n",
      "Trainable params: 23,876,778\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    # preprocessing_function=get_cutout_v2(),\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 1\n",
    "batch_size = 32\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('cifar10/cifar10v3/train_resized_299/',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('cifar10/cifar10v3/test_resized_299/',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('cifar10', 'cifar10v3', 'checkpoints', 'Cifar10_Share_4_Inception_ex23_01.hdf5')\n",
    "savedfilename_best = os.path.join('cifar10', 'cifar10v3', 'checkpoints', 'Cifar10_Share_4_Inception_ex23_01_best.hdf5')\n",
    "savedfilename_pre = os.path.join('cifar10', 'cifar10v3', 'checkpoints', 'Cifar10_Share_4_Inception_ex23_01_pre.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_accuracy', verbose=1, \n",
    "                          save_best_only=False, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_accuracy', value=0.9900, verbose=1)\n",
    "\n",
    "def rand_scheduler(epoch, lr):\n",
    "    rnd_lr = 10**(random.uniform(np.log10((1e-5)),np.log10((1e-1))))\n",
    "#     if epoch < 30:\n",
    "#         rnd_lr = 1e-2\n",
    "#     else:    \n",
    "#         rnd_lr = 1e-3\n",
    "##     rnd_lr = lr\n",
    "    print('random lr = ', rnd_lr)\n",
    "    return rnd_lr\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-2\n",
    "# decay = lr/epochs\n",
    "# optimizer = Adam(lr=lr, decay=decay)\n",
    "# optimizer = Adam(lr=lr)\n",
    "optimizer = SGD(lr=lr)\n",
    "\n",
    "# train on multiple-gpus\n",
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of GPUs: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    model_mul = get_adv_model()\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    # save initial model\n",
    "    model_mul.save_weights(savedfilename) \n",
    "    model_mul.save_weights(savedfilename_best)\n",
    "    model_mul.save_weights(savedfilename_pre)\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "# result = model_mul.fit_generator(\n",
    "#     generator = train_set, \n",
    "#     steps_per_epoch = step_size_train,\n",
    "#     validation_data = valid_set,\n",
    "#     validation_steps = step_size_valid,\n",
    "#     shuffle=True,\n",
    "#     epochs=epochs,\n",
    "#     callbacks=[checkpointer],\n",
    "# #     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "# #     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "#     verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "d = {'id': [1, 2, 3, 4], 'pbest_value': [0, 0, 0, 0], 'pbest_file':['Cifar10_Share_1_Inception_ex23_01_best.hdf5',\n",
    "                                                        'Cifar10_Share_2_Inception_ex23_01_best.hdf5',\n",
    "                                                        'Cifar10_Share_3_Inception_ex23_01_best.hdf5',\n",
    "                                                        'Cifar10_Share_4_Inception_ex23_01_best.hdf5'], \n",
    "                         'c_value': [0, 0, 0, 0], 'c_file':['Cifar10_Share_1_Inception_ex23_01.hdf5',\n",
    "                                                             'Cifar10_Share_2_Inception_ex23_01.hdf5',\n",
    "                                                             'Cifar10_Share_3_Inception_ex23_01.hdf5',\n",
    "                                                             'Cifar10_Share_4_Inception_ex23_01.hdf5'], \n",
    "                         'pre_value': [0, 0, 0, 0], 'pre_file':['Cifar10_Share_1_Inception_ex23_01_pre.hdf5',\n",
    "                                                             'Cifar10_Share_2_Inception_ex23_01_pre.hdf5',\n",
    "                                                             'Cifar10_Share_3_Inception_ex23_01_pre.hdf5',\n",
    "                                                             'Cifar10_Share_4_Inception_ex23_01_pre.hdf5'],\n",
    "                         'training_flag':[0, 0, 0, 0]\n",
    "    }\n",
    "df = pandas.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join('cifar10', 'cifar10v3', 'data_ex23_01.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = os.path.join('cifar10', 'cifar10v3', 'data_ex23_01.csv')\n",
    "\n",
    "def synch_read_data(data_file=''):\n",
    "    while(True):\n",
    "        try:\n",
    "            df = pandas.read_csv(data_file, index_col=0)  \n",
    "            break                     \n",
    "        except:\n",
    "            #waiting for 10s\n",
    "            print(\"\\n\")\n",
    "            for i in range(10,0,-1):\n",
    "                print(\"re-read the file ....%2d\" %i, end=\"\\r\", flush=True)\n",
    "                time.sleep(1) \n",
    "    return df  \n",
    "\n",
    "def synch_write_data(df,data_file=''):\n",
    "    while(True):\n",
    "        try:\n",
    "            df.to_csv(data_file)  \n",
    "            break                     \n",
    "        except:\n",
    "            #waiting for 10s\n",
    "            print(\"\\n\")\n",
    "            for i in range(10,0,-1):\n",
    "                print(\"re-read the file ....%2d\" %i, end=\"\\r\", flush=True)\n",
    "                time.sleep(1) \n",
    "    return df  \n",
    "\n",
    "def get_pbest_loc(row=0):\n",
    "    df = synch_read_data(data_file)\n",
    "    row=df.loc[row]\n",
    "    pbest_value = row[1]\n",
    "    file_name = row[2]\n",
    "    return pbest_value, file_name\n",
    "\n",
    "def set_pbest_loc(row, pbest_value):\n",
    "    df = synch_read_data(data_file)\n",
    "    df.loc[row, 'pbest_value'] = pbest_value\n",
    "    synch_write_data(df,data_file)\n",
    "    \n",
    "def get_c_loc(row=0):\n",
    "    df = synch_read_data(data_file)\n",
    "    row=df.loc[row]\n",
    "    c_value = row[3]\n",
    "    file_name = row[4]\n",
    "    return c_value, file_name\n",
    "\n",
    "def set_c_loc(row, c_value):\n",
    "    df = synch_read_data(data_file)\n",
    "    df.loc[row, 'c_value'] = c_value\n",
    "    synch_write_data(df,data_file)   \n",
    "\n",
    "#    \n",
    "def get_pre_loc(row=0):\n",
    "    df = synch_read_data(data_file)\n",
    "    row=df.loc[row]\n",
    "    pre_value = row[5]\n",
    "    file_name = row[6]\n",
    "    return pre_value, file_name\n",
    "\n",
    "def set_pre_loc(row, pre_value):\n",
    "    df = synch_read_data(data_file)\n",
    "    df.loc[row, 'pre_value'] = pre_value\n",
    "    synch_write_data(df,data_file)\n",
    "    \n",
    "#training flag\n",
    "def get_training_flag(row=0):\n",
    "    df = synch_read_data(data_file)\n",
    "    row=df.loc[row]\n",
    "    training_flag = row[7]\n",
    "    return training_flag\n",
    "\n",
    "def set_training_flag(row, training_status):\n",
    "    df = synch_read_data(data_file)\n",
    "    df.loc[row, 'training_flag'] = training_status\n",
    "    synch_write_data(df,data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance(w1, w2):\n",
    "    sqr_distance = 0\n",
    "    \n",
    "    w_np_1 = np.array(w1)\n",
    "    w_fl_1 = w_np_1.flatten()\n",
    "    w_np_2 = np.array(w2)\n",
    "    w_fl_2 = w_np_2.flatten()\n",
    "    \n",
    "    for i in range(len(w_np_1)):\n",
    "        x1_fl = w_fl_1[i].flatten()\n",
    "        x2_fl = w_fl_2[i].flatten()\n",
    "\n",
    "        tmp_dis = 0 \n",
    "        for j in range(len(x1_fl)):\n",
    "            tmp_dis = tmp_dis + (x1_fl[j]-x2_fl[j])**2\n",
    "\n",
    "    #     print(tmp_dis)\n",
    "        sqr_distance = sqr_distance + tmp_dis\n",
    "\n",
    "    return sqr_distance**(1/2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open a strategy scope.\n",
    "# with strategy.scope():\n",
    "#     model_mul.load_weights(os.path.join('surrey_share', 'C', 'checkpoints', 'Surrey_4_Share_MobileNet_v2_C.hdf5'))\n",
    "    \n",
    "# model_mul.evaluate(valid_set)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "WARNING:tensorflow:From <ipython-input-13-5a512cc855ea>:114: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "random lr =  0.0025670220676705423\n",
      "WARNING:tensorflow:From /home/bribeiro/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.1130 - accuracy: 0.6287\n",
      "Epoch 00001: saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_01.hdf5\n",
      "1563/1563 [==============================] - 1050s 672ms/step - loss: 1.1130 - accuracy: 0.6287 - val_loss: 0.3280 - val_accuracy: 0.8961\n",
      "0\n",
      "flg_i 0 flag 0\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 54.75597531644394), (1, 53.05555118955918), (2, 66.37835127441036), (3, 0)]\n",
      "distances  [(3, 0), (1, 53.05555118955918), (0, 54.75597531644394), (2, 66.37835127441036)]\n",
      "neighbors ids  [3, 1, 0, 2]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.8960999846458435\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.8826000094413757\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.9337000250816344\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.9020000100135804\n",
      "neighbor best  [(0, 0.9337000250816344), (2, 0.9020000100135804), (3, 0.8960999846458435), (1, 0.8826000094413757)]\n",
      "name_file_neighbor_best  Cifar10_Share_1_Inception_ex23_01_best.hdf5\n",
      "u  1.7\n",
      "distance_ij  53.05555118955918\n",
      "u  0.2\n",
      "distance_ij  54.75597531644394\n",
      "u  0.2\n",
      "distance_ij  66.37835127441036\n",
      "After ---> epoch= 0  r1= 0.09208614392803471  r2= 0.2703013737360458  current acc= 0.8960999846458435  local best= 0.8960999846458435  neighbor index= 0  neighbor best= 0.9337000250816344\n",
      "1\n",
      "random lr =  3.3257262599354435e-05\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6079 - accuracy: 0.8281\n",
      "Epoch 00001: saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_01.hdf5\n",
      "1563/1563 [==============================] - 942s 603ms/step - loss: 0.6079 - accuracy: 0.8281 - val_loss: 0.3666 - val_accuracy: 0.9133\n",
      "0\n",
      "flg_i 0 flag 1\n",
      "flg_i 1 flag 1\n",
      "flg_i 2 flag 1\n",
      "flg_i 3 flag 0\n",
      "\n",
      "\n",
      "flg_i 0 flag 0.. 1\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 49.23663189596703), (1, 41.82405119423501), (2, 61.181131638626795), (3, 0)]\n",
      "distances  [(3, 0), (1, 41.82405119423501), (0, 49.23663189596703), (2, 61.181131638626795)]\n",
      "neighbors ids  [3, 1, 0, 2]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.9132999777793884\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.9312999844551086\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.9520999789237976\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.926900029182434\n",
      "neighbor best  [(0, 0.9520999789237976), (1, 0.9312999844551086), (2, 0.926900029182434), (3, 0.9132999777793884)]\n",
      "name_file_neighbor_best  Cifar10_Share_1_Inception_ex23_01_best.hdf5\n",
      "u  1.7\n",
      "distance_ij  41.82405119423501\n",
      "u  0.2\n",
      "distance_ij  49.23663189596703\n",
      "u  0.2\n",
      "distance_ij  61.181131638626795\n",
      "After ---> epoch= 1  r1= 0.8633751596257824  r2= 0.3252188482568853  current acc= 0.9132999777793884  local best= 0.9132999777793884  neighbor index= 0  neighbor best= 0.9520999789237976\n",
      "1\n",
      "random lr =  0.00015484366401388077\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6205 - accuracy: 0.8581\n",
      "Epoch 00001: saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_01.hdf5\n",
      "1563/1563 [==============================] - 946s 605ms/step - loss: 0.6205 - accuracy: 0.8581 - val_loss: 0.3334 - val_accuracy: 0.9336\n",
      "0\n",
      "flg_i 0 flag 1\n",
      "flg_i 1 flag 1\n",
      "flg_i 2 flag 1\n",
      "flg_i 3 flag 0\n",
      "\n",
      "\n",
      "flg_i 0 flag 0.. 1\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 41.96523312865257), (1, 35.989620299303624), (2, 64.21025049700688), (3, 0)]\n",
      "distances  [(3, 0), (1, 35.989620299303624), (0, 41.96523312865257), (2, 64.21025049700688)]\n",
      "neighbors ids  [3, 1, 0, 2]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.9336000084877014\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.9512000083923341\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.9611999988555908\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.926900029182434\n",
      "neighbor best  [(0, 0.9611999988555908), (1, 0.9512000083923341), (3, 0.9336000084877014), (2, 0.926900029182434)]\n",
      "name_file_neighbor_best  Cifar10_Share_1_Inception_ex23_01_best.hdf5\n",
      "u  1.7\n",
      "distance_ij  35.989620299303624\n",
      "u  0.2\n",
      "distance_ij  41.96523312865257\n",
      "u  0.2\n",
      "distance_ij  64.21025049700688\n",
      "After ---> epoch= 2  r1= 0.5594768192730288  r2= 0.04323779745619338  current acc= 0.9336000084877014  local best= 0.9336000084877014  neighbor index= 0  neighbor best= 0.9611999988555908\n",
      "1\n",
      "random lr =  0.00012161974049040371\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5208 - accuracy: 0.8660\n",
      "Epoch 00001: saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_01.hdf5\n",
      "1563/1563 [==============================] - 948s 606ms/step - loss: 0.5208 - accuracy: 0.8660 - val_loss: 0.2772 - val_accuracy: 0.9391\n",
      "0\n",
      "flg_i 0 flag 1\n",
      "flg_i 1 flag 1\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "\n",
      "\n",
      "flg_i 0 flag 0.. 1\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 42.01226691446661), (1, 39.33371941146487), (2, 43.05292356169377), (3, 0)]\n",
      "distances  [(3, 0), (1, 39.33371941146487), (0, 42.01226691446661), (2, 43.05292356169377)]\n",
      "neighbors ids  [3, 1, 0, 2]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.9391000270843506\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.9512000083923341\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.9625999927520752\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.9587000012397766\n",
      "neighbor best  [(0, 0.9625999927520752), (2, 0.9587000012397766), (1, 0.9512000083923341), (3, 0.9391000270843506)]\n",
      "name_file_neighbor_best  Cifar10_Share_1_Inception_ex23_01_best.hdf5\n",
      "u  1.7\n",
      "distance_ij  39.33371941146487\n",
      "u  0.2\n",
      "distance_ij  42.01226691446661\n",
      "u  0.2\n",
      "distance_ij  43.05292356169377\n",
      "After ---> epoch= 3  r1= 0.3785869912597618  r2= 0.34691441656051036  current acc= 0.9391000270843506  local best= 0.9391000270843506  neighbor index= 0  neighbor best= 0.9625999927520752\n",
      "1\n",
      "random lr =  0.00021187684575434387\n",
      " 100/1563 [>.............................] - ETA: 13:48 - loss: 0.4950 - accuracy: 0.9072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 839/1563 [===============>..............] - ETA: 7:05 - loss: 0.1162 - accuracy: 0.9605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9688\n",
      "Epoch 00001: saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_01.hdf5\n",
      "1563/1563 [==============================] - 944s 604ms/step - loss: 0.0923 - accuracy: 0.9688 - val_loss: 0.0775 - val_accuracy: 0.9752\n",
      "0\n",
      "flg_i 0 flag 1\n",
      "flg_i 1 flag 1\n",
      "flg_i 2 flag 1\n",
      "flg_i 3 flag 0\n",
      "\n",
      "\n",
      "flg_i 0 flag 0.. 1\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 13.67706316497142), (1, 19.889675583543696), (2, 10.950323586379078), (3, 0)]\n",
      "distances  [(3, 0), (2, 10.950323586379078), (0, 13.67706316497142), (1, 19.889675583543696)]\n",
      "neighbors ids  [3, 2, 0, 1]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.9751999974250792\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.977999985218048\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.9747999906539916\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.975600004196167\n",
      "neighbor best  [(2, 0.977999985218048), (1, 0.975600004196167), (3, 0.9751999974250792), (0, 0.9747999906539916)]\n",
      "name_file_neighbor_best  Cifar10_Share_3_Inception_ex23_01_best.hdf5\n",
      "u  0.2\n",
      "distance_ij  10.950323586379078\n",
      "u  0.2\n",
      "distance_ij  13.67706316497142\n",
      "u  1.7\n",
      "distance_ij  19.889675583543696\n",
      "After ---> epoch= 10  r1= 0.6517821333761948  r2= 0.371933916634436  current acc= 0.9751999974250793  local best= 0.9751999974250793  neighbor index= 2  neighbor best= 0.977999985218048\n",
      "1\n",
      "random lr =  0.008907899255151189\n",
      "1034/1563 [==================>...........] - ETA: 5:07 - loss: 0.0882 - accuracy: 0.9702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9788\n",
      "Epoch 00001: saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_01.hdf5\n",
      "1563/1563 [==============================] - 944s 604ms/step - loss: 0.0625 - accuracy: 0.9788 - val_loss: 0.0713 - val_accuracy: 0.9765\n",
      "0\n",
      "flg_i 0 flag 0\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 1\n",
      "flg_i 3 flag 0\n",
      "\n",
      "\n",
      "flg_i 0 flag 0.. 1\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 12.727504598794997), (1, 8.710497576815447), (2, 12.22990436505882), (3, 0)]\n",
      "distances  [(3, 0), (1, 8.710497576815447), (2, 12.22990436505882), (0, 12.727504598794997)]\n",
      "neighbors ids  [3, 1, 2, 0]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.9776999950408936\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.9779000282287598\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.9786000251770021\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.9761000275611876\n",
      "neighbor best  [(2, 0.9786000251770021), (1, 0.9779000282287598), (3, 0.9776999950408936), (0, 0.9761000275611876)]\n",
      "name_file_neighbor_best  Cifar10_Share_3_Inception_ex23_01_best.hdf5\n",
      "u  1.7\n",
      "distance_ij  8.710497576815447\n",
      "u  0.2\n",
      "distance_ij  12.22990436505882\n",
      "u  0.2\n",
      "distance_ij  12.727504598794997\n",
      "After ---> epoch= 16  r1= 0.01767125252413604  r2= 0.5475899828425583  current acc= 0.9764999747276306  local best= 0.9776999950408936  neighbor index= 2  neighbor best= 0.9786000251770021\n",
      "1\n",
      "random lr =  0.00030523134754024554\n",
      "  55/1563 [>.............................] - ETA: 14:08 - loss: 0.0606 - accuracy: 0.9767"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9786\n",
      "Epoch 00001: saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_01.hdf5\n",
      "1563/1563 [==============================] - 946s 605ms/step - loss: 0.0618 - accuracy: 0.9786 - val_loss: 0.0721 - val_accuracy: 0.9776\n",
      "0\n",
      "flg_i 0 flag 1\n",
      "flg_i 1 flag 1\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "\n",
      "\n",
      "flg_i 0 flag 0.. 1\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 12.201465219091142), (1, 8.285858564793203), (2, 6.86157417429805), (3, 0)]\n",
      "distances  [(3, 0), (2, 6.86157417429805), (1, 8.285858564793203), (0, 12.201465219091142)]\n",
      "neighbors ids  [3, 2, 1, 0]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.9776999950408936\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.978600025177002\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.9779000282287598\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.9761000275611876\n",
      "neighbor best  [(2, 0.978600025177002), (1, 0.9779000282287598), (3, 0.9776999950408936), (0, 0.9761000275611876)]\n",
      "name_file_neighbor_best  Cifar10_Share_3_Inception_ex23_01_best.hdf5\n",
      "u  0.2\n",
      "distance_ij  6.86157417429805\n",
      "u  1.7\n",
      "distance_ij  8.285858564793203\n",
      "u  0.2\n",
      "distance_ij  12.201465219091142\n",
      "After ---> epoch= 17  r1= 0.3084390804669983  r2= 0.5452109192549484  current acc= 0.9775999784469604  local best= 0.9776999950408936  neighbor index= 2  neighbor best= 0.978600025177002\n",
      "1\n",
      "random lr =  1.3672217809167907e-05\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9802\n",
      "Epoch 00001: saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_01.hdf5\n",
      "1563/1563 [==============================] - 945s 605ms/step - loss: 0.0590 - accuracy: 0.9802 - val_loss: 0.0715 - val_accuracy: 0.9780\n",
      "0\n",
      "flg_i 0 flag 0\n",
      "flg_i 1 flag 1\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "\n",
      "\n",
      "flg_i 0 flag 0.. 1\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 8.975970682296547), (1, 4.503252287305014), (2, 4.552628546173401), (3, 0)]\n",
      "distances  [(3, 0), (1, 4.503252287305014), (2, 4.552628546173401), (0, 8.975970682296547)]\n",
      "neighbors ids  [3, 1, 2, 0]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.977999985218048\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.9783999919891356\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.9792000055313108\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.9761000275611876\n",
      "neighbor best  [(2, 0.9792000055313108), (1, 0.9783999919891356), (3, 0.977999985218048), (0, 0.9761000275611876)]\n",
      "name_file_neighbor_best  Cifar10_Share_3_Inception_ex23_01_best.hdf5\n",
      "u  1.7\n",
      "distance_ij  4.503252287305014\n",
      "u  0.2\n",
      "distance_ij  4.552628546173401\n",
      "u  0.2\n",
      "distance_ij  8.975970682296547\n",
      "After ---> epoch= 18  r1= 0.2536824188005713  r2= 0.8764772701623667  current acc= 0.9779999852180481  local best= 0.9779999852180481  neighbor index= 2  neighbor best= 0.9792000055313108\n",
      "1\n",
      "random lr =  3.606333738117205e-05\n",
      " 193/1563 [==>...........................] - ETA: 13:02 - loss: 0.0579 - accuracy: 0.9811"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1497/1563 [===========================>..] - ETA: 38s - loss: 0.0527 - accuracy: 0.9821"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9826\n",
      "Epoch 00001: saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_01.hdf5\n",
      "1563/1563 [==============================] - 952s 609ms/step - loss: 0.0518 - accuracy: 0.9826 - val_loss: 0.0696 - val_accuracy: 0.9790\n",
      "0\n",
      "flg_i 0 flag 0\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 10.458322239263419), (1, 3.835698053447146), (2, 14.61224782729308), (3, 0)]\n",
      "distances  [(3, 0), (1, 3.835698053447146), (0, 10.458322239263419), (2, 14.61224782729308)]\n",
      "neighbors ids  [3, 1, 0, 2]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.9792000055313108\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.9799000024795532\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.9764000177383424\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.9792000055313108\n",
      "neighbor best  [(1, 0.9799000024795532), (3, 0.9792000055313108), (2, 0.9792000055313108), (0, 0.9764000177383424)]\n",
      "name_file_neighbor_best  Cifar10_Share_2_Inception_ex23_01_best.hdf5\n",
      "u  1.7\n",
      "distance_ij  3.835698053447146\n",
      "u  0.2\n",
      "distance_ij  10.458322239263419\n",
      "u  0.2\n",
      "distance_ij  14.61224782729308\n",
      "After ---> epoch= 24  r1= 0.21555870425293988  r2= 0.744710576658723  current acc= 0.9789999723434448  local best= 0.979200005531311  neighbor index= 1  neighbor best= 0.9799000024795532\n",
      "1\n",
      "random lr =  0.013078195969814592\n",
      " 358/1563 [=====>........................] - ETA: 11:11 - loss: 0.0542 - accuracy: 0.9812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9762\n",
      "Epoch 00001: saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_01.hdf5\n",
      "1563/1563 [==============================] - 938s 600ms/step - loss: 0.0681 - accuracy: 0.9762 - val_loss: 0.0851 - val_accuracy: 0.9741\n",
      "0\n",
      "flg_i 0 flag 1\n",
      "flg_i 1 flag 1\n",
      "flg_i 2 flag 1\n",
      "flg_i 3 flag 0\n",
      "\n",
      "\n",
      "flg_i 0 flag 1.. 1\n",
      "flg_i 1 flag 1\n",
      "flg_i 2 flag 1\n",
      "flg_i 3 flag 0\n",
      "\n",
      "\n",
      "flg_i 0 flag 0.. 1\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 10.784520135164962), (1, 5.772365657126221), (2, 9.608689078486002), (3, 0)]\n",
      "distances  [(3, 0), (1, 5.772365657126221), (2, 9.608689078486002), (0, 10.784520135164962)]\n",
      "neighbors ids  [3, 1, 2, 0]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.9792000055313108\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.9799000024795532\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.9792000055313108\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.9764000177383424\n",
      "neighbor best  [(1, 0.9799000024795532), (3, 0.9792000055313108), (2, 0.9792000055313108), (0, 0.9764000177383424)]\n",
      "name_file_neighbor_best  Cifar10_Share_2_Inception_ex23_01_best.hdf5\n",
      "u  1.7\n",
      "distance_ij  5.772365657126221\n",
      "u  0.2\n",
      "distance_ij  9.608689078486002\n",
      "u  0.2\n",
      "distance_ij  10.784520135164962\n",
      "After ---> epoch= 25  r1= 0.9184681677844528  r2= 0.843881669253926  current acc= 0.9740999937057495  local best= 0.979200005531311  neighbor index= 1  neighbor best= 0.9799000024795532\n",
      "1\n",
      "random lr =  0.0008082650983177539\n",
      "1065/1563 [===================>..........] - ETA: 4:50 - loss: 0.0492 - accuracy: 0.9833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flg_i 0 flag 0.. 1\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 10.841997362028907), (1, 13.114136344675089), (2, 13.22421280120047), (3, 0)]\n",
      "distances  [(3, 0), (0, 10.841997362028907), (1, 13.114136344675089), (2, 13.22421280120047)]\n",
      "neighbors ids  [3, 0, 1, 2]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.9792000055313108\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.9764000177383424\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.9799000024795532\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.9793999791145324\n",
      "neighbor best  [(1, 0.9799000024795532), (2, 0.9793999791145324), (3, 0.9792000055313108), (0, 0.9764000177383424)]\n",
      "name_file_neighbor_best  Cifar10_Share_2_Inception_ex23_01_best.hdf5\n",
      "u  0.2\n",
      "distance_ij  10.841997362028907\n",
      "u  1.7\n",
      "distance_ij  13.114136344675089\n",
      "u  0.2\n",
      "distance_ij  13.22421280120047\n",
      "After ---> epoch= 30  r1= 0.6160318036588551  r2= 0.9538423218650977  current acc= 0.9728000164031982  local best= 0.979200005531311  neighbor index= 1  neighbor best= 0.9799000024795532\n",
      "1\n",
      "random lr =  0.00012587801148068834\n",
      " 698/1563 [============>.................] - ETA: 8:19 - loss: 0.0566 - accuracy: 0.9807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1563 [=====================>........] - ETA: 3:40 - loss: 0.0536 - accuracy: 0.9815"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9816\n",
      "Epoch 00001: saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_01.hdf5\n",
      "1563/1563 [==============================] - 941s 602ms/step - loss: 0.0536 - accuracy: 0.9816 - val_loss: 0.0708 - val_accuracy: 0.9794\n",
      "0\n",
      "flg_i 0 flag 0\n",
      "flg_i 1 flag 1\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "\n",
      "\n",
      "flg_i 0 flag 0.. 1\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 7.8406283802330305), (1, 5.745455964731381), (2, 11.4877530784861), (3, 0)]\n",
      "distances  [(3, 0), (1, 5.745455964731381), (0, 7.8406283802330305), (2, 11.4877530784861)]\n",
      "neighbors ids  [3, 1, 0, 2]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.9793999791145324\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.9799000024795532\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.977999985218048\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.9793999791145324\n",
      "neighbor best  [(1, 0.9799000024795532), (3, 0.9793999791145324), (2, 0.9793999791145324), (0, 0.977999985218048)]\n",
      "name_file_neighbor_best  Cifar10_Share_2_Inception_ex23_01_best.hdf5\n",
      "u  1.7\n",
      "distance_ij  5.745455964731381\n",
      "u  0.2\n",
      "distance_ij  7.8406283802330305\n",
      "u  0.2\n",
      "distance_ij  11.4877530784861\n",
      "After ---> epoch= 33  r1= 0.5117326542798857  r2= 0.08815211525137856  current acc= 0.9793999791145325  local best= 0.9793999791145325  neighbor index= 1  neighbor best= 0.9799000024795532\n",
      "1\n",
      "random lr =  0.01106674517636467\n",
      " 251/1563 [===>..........................] - ETA: 12:31 - loss: 0.0571 - accuracy: 0.9819"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9843\n",
      "Epoch 00001: saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_01.hdf5\n",
      "1563/1563 [==============================] - 947s 606ms/step - loss: 0.0475 - accuracy: 0.9843 - val_loss: 0.0699 - val_accuracy: 0.9793\n",
      "0\n",
      "flg_i 0 flag 1\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "\n",
      "\n",
      "flg_i 0 flag 0.. 1\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 9.67530613250496), (1, 3.3913153795641735), (2, 4.762232760965966), (3, 0)]\n",
      "distances  [(3, 0), (1, 3.3913153795641735), (2, 4.762232760965966), (0, 9.67530613250496)]\n",
      "neighbors ids  [3, 1, 2, 0]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.9793999791145324\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.9804000258445741\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.9793999791145324\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.977999985218048\n",
      "neighbor best  [(1, 0.9804000258445741), (3, 0.9793999791145324), (2, 0.9793999791145324), (0, 0.977999985218048)]\n",
      "name_file_neighbor_best  Cifar10_Share_2_Inception_ex23_01_best.hdf5\n",
      "u  1.7\n",
      "distance_ij  3.3913153795641735\n",
      "u  0.2\n",
      "distance_ij  4.762232760965966\n",
      "u  0.2\n",
      "distance_ij  9.67530613250496\n",
      "After ---> epoch= 37  r1= 0.6624904741207681  r2= 0.3499882457517105  current acc= 0.9793000221252441  local best= 0.9793999791145325  neighbor index= 1  neighbor best= 0.9804000258445741\n",
      "1\n",
      "random lr =  0.015638826923849096\n",
      " 330/1563 [=====>........................] - ETA: 11:58 - loss: 0.0517 - accuracy: 0.9824"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9772\n",
      "Epoch 00001: saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_01.hdf5\n",
      "1563/1563 [==============================] - 946s 605ms/step - loss: 0.0673 - accuracy: 0.9772 - val_loss: 0.0878 - val_accuracy: 0.9729\n",
      "0\n",
      "flg_i 0 flag 0\n",
      "flg_i 1 flag 0\n",
      "flg_i 2 flag 0\n",
      "flg_i 3 flag 0\n",
      "end of waiting\n",
      "distances unsorted [(0, 9.406361499062486), (1, 6.916954940205785), (2, 8.470322360480317), (3, 0)]\n",
      "distances  [(3, 0), (1, 6.916954940205785), (2, 8.470322360480317), (0, 9.406361499062486)]\n",
      "neighbors ids  [3, 1, 2, 0]\n",
      "neighbor_idx  3\n",
      "neighbor_best_tmp  0.9793999791145324\n",
      "neighbor_idx  1\n",
      "neighbor_best_tmp  0.980400025844574\n",
      "neighbor_idx  2\n",
      "neighbor_best_tmp  0.9793999791145324\n",
      "neighbor_idx  0\n",
      "neighbor_best_tmp  0.977999985218048\n",
      "neighbor best  [(1, 0.980400025844574), (3, 0.9793999791145324), (2, 0.9793999791145324), (0, 0.977999985218048)]\n",
      "name_file_neighbor_best  Cifar10_Share_2_Inception_ex23_01_best.hdf5\n",
      "u  1.7\n",
      "distance_ij  6.916954940205785\n",
      "u  0.2\n",
      "distance_ij  8.470322360480317\n",
      "u  0.2\n",
      "distance_ij  9.406361499062486\n",
      "After ---> epoch= 38  r1= 0.6930701583927905  r2= 0.633133703162643  current acc= 0.9728999733924866  local best= 0.9793999791145325  neighbor index= 1  neighbor best= 0.980400025844574\n",
      "1\n",
      "random lr =  0.0014600298451746408\n",
      " 881/1563 [===============>..............] - ETA: 6:32 - loss: 0.0513 - accuracy: 0.9828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import keras\n",
    "import math\n",
    "\n",
    "#index of this pso\n",
    "pso_index = 3\n",
    "\n",
    "#number of neighbors (max=4)\n",
    "num_neighbors = 4\n",
    "#K coefficient\n",
    "M = 1\n",
    "u = 1\n",
    "\n",
    "tmp_acc = 0\n",
    "tmp_w = []\n",
    "pbest_acc = 0\n",
    "pbest_w = []\n",
    "\n",
    "#accelerator coefficient\n",
    "c1 = 0.5\n",
    "c2 = 0.5\n",
    "# w = 0.5\n",
    "\n",
    "r1 = 0\n",
    "r2 = 0\n",
    "\n",
    "results_stack_accuracy = []\n",
    "results_stack_val_accuracy = []\n",
    "results_stack_loss = []\n",
    "results_stack_val_loss = []\n",
    "\n",
    "#threshold\n",
    "# threshold = 0.97\n",
    "\n",
    "# #iteration control\n",
    "# i = 0\n",
    "# iter_max = 40\n",
    "\n",
    "warm_up = 0\n",
    "\n",
    "for index in range(0,warm_up):\n",
    "# while gbest_acc < threshold:\n",
    "    #save previous weight\n",
    "    model_mul.save_weights(savedfilename_pre)\n",
    "    result = model_mul.fit_generator(\n",
    "        generator = train_set, \n",
    "        steps_per_epoch = step_size_train,\n",
    "        validation_data = valid_set,\n",
    "        validation_steps = step_size_valid,\n",
    "        shuffle=True,\n",
    "        epochs=1,\n",
    "        callbacks=[checkpointer,tf.keras.callbacks.LearningRateScheduler(rand_scheduler)],\n",
    "    #     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "    #     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "        verbose=1) \n",
    "    \n",
    "    #save weights every iteration\n",
    "#     model_mul.save_weights(savedfilename)   \n",
    "    \n",
    "    tmp_acc = result.history.get('val_accuracy')[-1]\n",
    "    tmp_w = model_mul.get_weights()\n",
    "    tmp_lr = result.history.get('lr')[-1]\n",
    "    \n",
    "    #save current location\n",
    "    set_c_loc(pso_index,tmp_acc) \n",
    "    \n",
    "    if tmp_acc > pbest_acc:\n",
    "        pbest_acc = tmp_acc\n",
    "        pbest_w = tmp_w\n",
    "        #save person best location\n",
    "        set_pbest_loc(pso_index,pbest_acc)  \n",
    "        # save best model\n",
    "        model_mul.save_weights(savedfilename_best) \n",
    "    \n",
    "    results_stack_val_accuracy.append(result.history.get('val_accuracy')[-1])\n",
    "    results_stack_accuracy.append(result.history.get('accuracy')[-1])\n",
    "    results_stack_val_loss.append(result.history.get('val_loss')[-1])      \n",
    "    results_stack_loss.append(result.history.get('loss')[-1])\n",
    "    \n",
    "#     i = i + 1\n",
    "#     #exit after iteration gets max\n",
    "#     if i > iter_max:\n",
    "#         break\n",
    "\n",
    "#    \n",
    "# time synchronize\n",
    "number_of_pso = 4\n",
    "training_start_flag = 1\n",
    "training_finish_flag = 0\n",
    "\n",
    "#set initial training flag to start\n",
    "set_training_flag(pso_index, training_start_flag)\n",
    "\n",
    "for index in range(warm_up, epochs): \n",
    "# while i < iter_max:\n",
    "    #start training \n",
    "    set_training_flag(pso_index, training_start_flag)\n",
    "    print(get_training_flag(pso_index))\n",
    "    \n",
    "    #save previous weight\n",
    "    model_mul.save_weights(savedfilename_pre) \n",
    "    \n",
    "    result = model_mul.fit_generator(\n",
    "        generator = train_set, \n",
    "        steps_per_epoch = step_size_train,\n",
    "        validation_data = valid_set,\n",
    "        validation_steps = step_size_valid,\n",
    "        shuffle=True,\n",
    "        epochs=1,\n",
    "        callbacks=[checkpointer,tf.keras.callbacks.LearningRateScheduler(rand_scheduler)],\n",
    "    #     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "    #     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "        verbose=1) \n",
    "    \n",
    "    #save weights every iteration\n",
    "#     model_mul.save_weights(savedfilename)\n",
    "    \n",
    "    tmp_acc = result.history.get('val_accuracy')[-1]\n",
    "    tmp_w = model_mul.get_weights()\n",
    "    tmp_lr = result.history.get('lr')[-1]\n",
    "    \n",
    "    #save current location in scoreboard\n",
    "    set_c_loc(pso_index,tmp_acc) \n",
    "    \n",
    "    if tmp_acc > pbest_acc:\n",
    "        pbest_acc = tmp_acc\n",
    "        pbest_w = tmp_w\n",
    "        #save person best location\n",
    "        set_pbest_loc(pso_index,pbest_acc)  \n",
    "        # save best model\n",
    "        model_mul.save_weights(savedfilename_best)        \n",
    "\n",
    "    #set training flag to finish\n",
    "    set_training_flag(pso_index, training_finish_flag)  \n",
    "    print(get_training_flag(pso_index))\n",
    "        \n",
    "    # check if all PSOs is ready (flag==1)\n",
    "    while(True):\n",
    "        tmp_flag = 0\n",
    "        for flg_i in range(number_of_pso):\n",
    "            print(\"flg_i\", flg_i, \"flag\", get_training_flag(flg_i))\n",
    "            if(get_training_flag(flg_i) == 1):\n",
    "                tmp_flag = 1\n",
    "        if(tmp_flag==1):\n",
    "            #waiting for 60s\n",
    "            print(\"\\n\")\n",
    "            for i in range(60,0,-1):\n",
    "                print(\"waiting for ....%2d\" %i, end=\"\\r\", flush=True)\n",
    "                time.sleep(1)    \n",
    "        else:\n",
    "            print(\"end of waiting\")\n",
    "            break  \n",
    "    \n",
    "    r1 = random.uniform(0,1)\n",
    "    r2 = random.uniform(0,1)\n",
    "#     r3 = random.uniform(0,1)    \n",
    "    \n",
    "    #-----------nearest neighbor best--------------\n",
    "    #get neighbor weights\n",
    "    #1\n",
    "    neighbor_c_acc_1, name_file_1 = get_c_loc(0)\n",
    "    neighbor_c_acc_2, name_file_2 = get_c_loc(1)\n",
    "    neighbor_c_acc_3, name_file_3 = get_c_loc(2)\n",
    "    neighbor_c_acc_4, name_file_4 = get_c_loc(3)\n",
    "    \n",
    "    #get pre loc\n",
    "    neighbor_pre_acc_1, name_pre_file_1 = get_pre_loc(0)\n",
    "    neighbor_pre_acc_2, name_pre_file_2 = get_pre_loc(1)\n",
    "    neighbor_pre_acc_3, name_pre_file_3 = get_pre_loc(2)\n",
    "    neighbor_pre_acc_4, name_pre_file_4 = get_pre_loc(3)  \n",
    "    \n",
    "    #clone model for weights change\n",
    "    model_clone = keras.models.clone_model(model_mul)\n",
    "    \n",
    "    model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_file_1))\n",
    "    neighbor_w_1 = model_clone.get_weights() \n",
    "    model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_file_2))\n",
    "    neighbor_w_2 = model_clone.get_weights()\n",
    "    model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_file_3))\n",
    "    neighbor_w_3 = model_clone.get_weights()\n",
    "    model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_file_4))\n",
    "    neighbor_w_4 = model_clone.get_weights()\n",
    "    \n",
    "    #clone model pre weights\n",
    "    model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_pre_file_1))\n",
    "    neighbor_pre_w_1 = model_clone.get_weights()     \n",
    "    model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_pre_file_2))\n",
    "    neighbor_pre_w_2 = model_clone.get_weights() \n",
    "    model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_pre_file_3))\n",
    "    neighbor_pre_w_3 = model_clone.get_weights()    \n",
    "    model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_pre_file_4))\n",
    "    neighbor_pre_w_4 = model_clone.get_weights()  \n",
    "    \n",
    "    distance_1 = find_distance(neighbor_w_4,neighbor_w_1)\n",
    "    distance_2 = find_distance(neighbor_w_4,neighbor_w_2)\n",
    "    distance_3 = find_distance(neighbor_w_4,neighbor_w_3)\n",
    "    \n",
    "    #find the closest neighbor\n",
    "    distances = list()\n",
    "    distances.append((0,distance_1))\n",
    "    distances.append((1,distance_2))\n",
    "    distances.append((2,distance_3))\n",
    "    distances.append((3,0))\n",
    "\n",
    "    print('distances unsorted', distances)\n",
    "    \n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    print('distances ', distances)\n",
    "    \n",
    "    neighbors_idx = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors_idx.append(distances[i][0])        \n",
    "    \n",
    "    print('neighbors ids ', neighbors_idx)\n",
    "    \n",
    "    #get neighbor bests from the list\n",
    "    neighbor_bests = list()\n",
    "    #remove first element (self distance)\n",
    "#     neighbors_idx.pop(0)\n",
    "    \n",
    "    for i in range(len(neighbors_idx)):\n",
    "        neighbor_best_tmp, name_file_neighbor_best_tmp = get_pbest_loc(neighbors_idx[i])\n",
    "        neighbor_bests.append((neighbors_idx[i],neighbor_best_tmp))\n",
    "        print('neighbor_idx ', neighbors_idx[i])\n",
    "        print('neighbor_best_tmp ', neighbor_best_tmp)\n",
    "\n",
    "    # keep unsorted list of neighbor\n",
    "    neighbor_tmp = deepcopy(neighbor_bests)       \n",
    "    \n",
    "    # sort the list for maximum accuracy   \n",
    "    neighbor_bests.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    print('neighbor best ', neighbor_bests)\n",
    "    #\n",
    "    neighbor_best_value, name_file_neighbor_best = get_pbest_loc(neighbor_bests[0][0])\n",
    "    print('name_file_neighbor_best ', name_file_neighbor_best)\n",
    "    \n",
    "    model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_file_neighbor_best))\n",
    "    neighbor_best_w = model_clone.get_weights()  \n",
    "    #---------- end nearest neighbor best ----------\n",
    "    \n",
    "    #---------- cucker -----------------------------\n",
    "    particle_w_i = neighbor_w_4\n",
    "    sum_particle_tmp = 0\n",
    "    \n",
    "    #remove the fist (self)\n",
    "    neighbor_tmp.pop(0)\n",
    "    \n",
    "    for j in range(len(neighbor_tmp)):\n",
    "        if neighbor_tmp[j][0]==0:\n",
    "            particle_w_j = neighbor_w_1\n",
    "            particle_w_pre_j = neighbor_pre_w_1\n",
    "            distance_ij = distance_1\n",
    "            u = 0.2\n",
    "        elif neighbor_tmp[j][0]==1:    \n",
    "            particle_w_j = neighbor_w_2\n",
    "            particle_w_pre_j = neighbor_pre_w_2\n",
    "            distance_ij = distance_2\n",
    "            u = 1.7\n",
    "        elif neighbor_tmp[j][0]==2:    \n",
    "            particle_w_j = neighbor_w_3\n",
    "            particle_w_pre_j = neighbor_pre_w_3\n",
    "            distance_ij = distance_3\n",
    "            u = 0.2\n",
    "            \n",
    "        print('u ', u)\n",
    "        print('distance_ij ', distance_ij)\n",
    "        #sum(K/(1+distance)*(particle_w_j-particle_w_i)\n",
    "        sum_particle_tmp -= M*u/(1+distance_ij)*(np.array(particle_w_pre_j)-np.array(particle_w_j)) \n",
    "        \n",
    "    #---------- end cucker -------------------------\n",
    "\n",
    "    #update networks' weights\n",
    "    #     w = c1*r1*(np.array(pbest_w)-np.array(tmp_w))+c2*r2*(np.array(gbest_w)-np.array(tmp_w))\n",
    "    #     w = r1*np.array(pbest_w)+r2*np.array(tmp_w)+r3*np.array(gbest_w)\n",
    "    #     w = np.array(tmp_w)+tmp_lr*(c1*r1*(np.array(pbest_w)-np.array(tmp_w))+c2*r2*(np.array(gbest_w)-np.array(tmp_w)))\n",
    "#     final_weight = np.array(tmp_w)+sum_particle_tmp+c2*r2*(np.array(neighbor_best_w)-np.array(tmp_w))\n",
    "#     final_weight = np.array(tmp_w)+sum_particle_tmp\n",
    "\n",
    "#     final_weight = np.array(tmp_w)+c2*r2*(np.array(neighbor_best_w)-np.array(tmp_w))\n",
    "#     final_weight = np.array(tmp_w)+sum_particle_tmp+c1*r1*(np.array(pbest_w)-np.array(tmp_w))+c2*r2*(np.array(neighbor_best_w)-np.array(tmp_w))\n",
    "    final_weight = np.array(tmp_w)+sum_particle_tmp+c2*r2*(np.array(neighbor_best_w)-np.array(tmp_w))\n",
    "#     final_weight = np.array(tmp_w)+c2*r2*(np.array(neighbor_best_w)-np.array(tmp_w))\n",
    "#     final_weight = np.array(tmp_w)+sum_particle_tmp\n",
    "    \n",
    "    model_mul.set_weights(final_weight)\n",
    "    \n",
    "    print('After ---> epoch=', index, ' r1=',r1, ' r2=',r2, ' current acc=', tmp_acc, ' local best=', pbest_acc, \n",
    "          ' neighbor index=', neighbor_bests[0][0], ' neighbor best=', neighbor_best_value)  \n",
    "    \n",
    "    results_stack_val_accuracy.append(result.history.get('val_accuracy')[-1])\n",
    "    results_stack_accuracy.append(result.history.get('accuracy')[-1])\n",
    "    results_stack_val_loss.append(result.history.get('val_loss')[-1])      \n",
    "    results_stack_loss.append(result.history.get('loss')[-1])\n",
    "    \n",
    "#     i = i + 1\n",
    "        \n",
    "print(results_stack_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8960999846458435, 0.9132999777793884, 0.9336000084877014, 0.9391000270843506, 0.953499972820282, 0.9581999778747559, 0.9674000144004822, 0.9355000257492065, 0.9699000120162964, 0.9707000255584717, 0.9751999974250793, 0.9745000004768372, 0.9749000072479248, 0.9757000207901001, 0.9764999747276306, 0.9776999950408936, 0.9764999747276306, 0.9775999784469604, 0.9779999852180481, 0.9787999987602234, 0.9789999723434448, 0.9782000184059143, 0.979200005531311, 0.9787999987602234, 0.9789999723434448, 0.9740999937057495, 0.9783999919891357, 0.9787999987602234, 0.9200000166893005, 0.9672999978065491, 0.9728000164031982, 0.9786999821662903, 0.9793000221252441, 0.9793999791145325, 0.9758999943733215, 0.9789000153541565, 0.9793999791145325, 0.9793000221252441, 0.9728999733924866, 0.9775000214576721]\n"
     ]
    }
   ],
   "source": [
    "print(results_stack_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3280269205570221, 0.3666203022003174, 0.33343738317489624, 0.2771528661251068, 0.21004919707775116, 0.13433770835399628, 0.10229028016328812, 0.2025778591632843, 0.09476003795862198, 0.08948495239019394, 0.0774889811873436, 0.08410200476646423, 0.07958817481994629, 0.08123274892568588, 0.07401470094919205, 0.07057758420705795, 0.07127586007118225, 0.07214220613241196, 0.07151319086551666, 0.06923538446426392, 0.06882395595312119, 0.07134447991847992, 0.07029145210981369, 0.07072562724351883, 0.06963204592466354, 0.08512447774410248, 0.07076036930084229, 0.06973659992218018, 0.24893076717853546, 0.11056151986122131, 0.09228119254112244, 0.07370172441005707, 0.07085273414850235, 0.0707823857665062, 0.0813736692070961, 0.07267951220273972, 0.07059716433286667, 0.06989483535289764, 0.0878135934472084, 0.07380657643079758]\n"
     ]
    }
   ],
   "source": [
    "print(results_stack_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1130200624465942, 0.6079416871070862, 0.6204835772514343, 0.5208418369293213, 0.4380580484867096, 0.23760956525802612, 0.17084482312202454, 0.24839045107364655, 0.14539700746536255, 0.11523867398500443, 0.09226810187101364, 0.0903577134013176, 0.08116817474365234, 0.07988613098859787, 0.06591491401195526, 0.06035308167338371, 0.06248645856976509, 0.0618380606174469, 0.059008318930864334, 0.055074188858270645, 0.054854102432727814, 0.0530930794775486, 0.05347777158021927, 0.052506864070892334, 0.05182695761322975, 0.06814458221197128, 0.04930279776453972, 0.04813161492347717, 0.34437206387519836, 0.1260470300912857, 0.09635695070028305, 0.059432223439216614, 0.05320306494832039, 0.05355833098292351, 0.06115248426795006, 0.051699962466955185, 0.04802050441503525, 0.047464124858379364, 0.06726720929145813, 0.05006742849946022]\n"
     ]
    }
   ],
   "source": [
    "print(results_stack_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8960999846458435, 0.9132999777793884, 0.9336000084877014, 0.9391000270843506, 0.953499972820282, 0.9581999778747559, 0.9674000144004822, 0.9355000257492065, 0.9699000120162964, 0.9707000255584717, 0.9751999974250793, 0.9745000004768372, 0.9749000072479248, 0.9757000207901001, 0.9764999747276306, 0.9776999950408936, 0.9764999747276306, 0.9775999784469604, 0.9779999852180481, 0.9787999987602234, 0.9789999723434448, 0.9782000184059143, 0.979200005531311, 0.9787999987602234, 0.9789999723434448, 0.9740999937057495, 0.9783999919891357, 0.9787999987602234, 0.9200000166893005, 0.9672999978065491, 0.9728000164031982, 0.9786999821662903, 0.9793000221252441, 0.9793999791145325, 0.9758999943733215, 0.9789000153541565, 0.9793999791145325, 0.9793000221252441, 0.9728999733924866, 0.9775000214576721]\n"
     ]
    }
   ],
   "source": [
    "print(results_stack_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.history.get('val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.history.get('val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.history.get('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=1,\n",
    "#     callbacks=[checkpointer],\n",
    "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen_1 = ImageDataGenerator(\n",
    "    # rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    "    # preprocessing_function=get_random_eraser()\n",
    "    # preprocessing_function=get_cutout_v2()\n",
    ")\n",
    "\n",
    "# train_datagen_2 = ImageDataGenerator(\n",
    "#     # rescale = 1./255,\n",
    "#     rotation_range=30,\n",
    "#     width_shift_range=0.3,\n",
    "#     height_shift_range=0.3,\n",
    "#     shear_range=0.3,\n",
    "#     zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "# #     brightness_range=[0.5, 1.5],##\n",
    "#     channel_shift_range=10,##\n",
    "#     fill_mode='nearest',\n",
    "#     preprocessing_function=preprocess_input,\n",
    "#     # preprocessing_function=get_random_eraser()\n",
    "#     # preprocessing_function=get_cutout_v2()\n",
    "# )\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    # rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 24\n",
    "\n",
    "#\n",
    "train_set_1 = train_datagen_1.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "# #\n",
    "# train_set_2 = train_datagen_2.flow_from_directory('train_resized_299',\n",
    "#                                                  target_size = (299, 299),\n",
    "#                                                  batch_size = batch_size,\n",
    "#                                                  class_mode = 'categorical',\n",
    "#                                                  shuffle=True,\n",
    "#                                                  seed=7,\n",
    "# #                                                  subset=\"training\"\n",
    "#                                               )\n",
    "\n",
    "# # Train Generator (CutMix)\n",
    "# train_set_collage = CutMixImageDataGenerator(\n",
    "#     generator1=train_set_1,\n",
    "#     generator2=train_set_2,\n",
    "#     img_size=299,\n",
    "#     batch_size=batch_size,\n",
    "# )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints','Cifar10_EfficientNetB7_299_STD_tmp.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar10_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar10_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.9900, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "else:\n",
    "    model_mul = model_1\n",
    "    \n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set_1.n/train_set_1.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set_1, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar10_EfficientNetB7_299_STD.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "id": "9it_mwRMLe-e",
    "outputId": "793a2e4b-544c-485f-b030-a2460c523a9b"
   },
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar10_EfficientNetB7_299_STD_L2.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set_1, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar10_EfficientNetB7_299_STD_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar10_EfficientNetB7_299_STD_L3.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set_1, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZBm5kY_TxMv"
   },
   "outputs": [],
   "source": [
    "# #Using multiple models if more than 1 GPU\n",
    "# NUM_GPU = 4\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar10_EfficientNetB7_299_STD_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 40\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar10_EfficientB7_299_STD_2708.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_Eff_B5_345_1511_v1.csv /home/bribeiro/Phong/Nat19/Cifar10_Eff_B5_345_1511_v1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar10_EfficientB7_299_STD_L3.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 72\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "test_datagen_crop = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "testing_set_crop = test_datagen_crop.flow_from_directory('test_resized_345',\n",
    "                                                 target_size = (370, 370),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "#customized generator\n",
    "test_crops = crop_generator(testing_set_crop, 345)\n",
    "\n",
    "step_size_test_crop = ceil(testing_set_crop.n/testing_set_crop.batch_size)\n",
    "\n",
    "tta_steps = 4\n",
    "# predictions = []\n",
    "\n",
    "# import tensorflow as tf\n",
    "# with tf.device('/gpu:0'):\n",
    "for i in range(tta_steps):\n",
    "    print(i)\n",
    "    testing_set_crop.reset()\n",
    "    if NUM_GPU != 1:\n",
    "        preds=model_mul.predict_generator(test_crops, \n",
    "                                           steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "#                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "                                           verbose=1)    \n",
    "#     else:\n",
    "#         preds=model.predict_generator(test_crops, \n",
    "#                                            steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "# #                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "#                                            verbose=1)  \n",
    "#     preds=model_2.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "    predictions.append(preds)\n",
    "\n",
    "mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cifar10_Eff_B5_345_STD_tta_7.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_Eff_B5_345_STD_tta_7.csv /home/bribeiro/Phong/Nat19/Cifar10_Eff_B5_345_STD_tta_7.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar10_Eff_B5_345_L2_TTA3.npy'), mean_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_Eff_B7_299_STD_L3.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Using multiple models if more than 1 GPU\n",
    "# NUM_GPU = 4\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_Eff_B7_299_STD_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 36\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar100_Eff_B0_299_1108_v1.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar100_Eff_B7_299_STD_L3.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar10_efficientnet_B5_345_T2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
