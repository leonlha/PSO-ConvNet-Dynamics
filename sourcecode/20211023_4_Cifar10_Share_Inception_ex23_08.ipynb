{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "IBQ_eVTu8OnB",
    "outputId": "a0117324-8e60-4944-c431-14ed244b4f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14337719835102464900\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5933828632867285066\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6620187864523702060\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10748822848\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11252821742535965375\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "LP5lidXD8ViI",
    "outputId": "2ff8199e-96f9-40cd-dd5b-e85cb49178c2"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rYOoAdFk8ma3",
    "outputId": "4e860915-8468-45db-fbcf-be0d20e5c2df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/datastorage/Phong\n"
     ]
    }
   ],
   "source": [
    "cd /media/datastorage/Phong/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "mDdxdcwj8ozr",
    "outputId": "68605cb6-d5ad-42dd-ce42-3e58e2b7b5db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7191252\r\n",
      "drwxrwxr-x 20 bribeiro bribeiro       4096 ago 23  2019 \u001b[0m\u001b[01;34mcassava\u001b[0m/\r\n",
      "drwxrwxr-x  5 bribeiro bribeiro       4096 mar 18  2021 \u001b[01;34mcifar10\u001b[0m/\r\n",
      "drwxrwxr-x 15 bribeiro bribeiro       4096 set  3  2020 \u001b[01;34mcifar100_png\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro  169001437 ago  8  2020 \u001b[01;31mcifar-100-python.tar.gz\u001b[0m\r\n",
      "drwxr-xr-x  2 bribeiro bribeiro       4096 fev  6  2021 \u001b[01;34mdataset5\u001b[0m/\r\n",
      "drwxrwxr-x 15 bribeiro bribeiro       4096 set  3  2019 \u001b[01;34mDogAge\u001b[0m/\r\n",
      "drwxrwxr-x 17 bribeiro bribeiro       4096 ago  8  2020 \u001b[01;34mfashion_mnist\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro 2246539027 fev  4  2021 \u001b[01;31mfingerspelling5.tar.bz2\u001b[0m\r\n",
      "drwxrwxr-x  6 bribeiro bribeiro       4096 ago  5  2019 \u001b[01;34mImageNet\u001b[0m/\r\n",
      "drwxrwxr-x  3 bribeiro bribeiro       4096 fev 24  2021 \u001b[01;34mImageNet2\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro  793579520 out 20  2011 \u001b[01;31mimages.tar\u001b[0m\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro  182349464 set 22  2019 \u001b[01;31mlibcudnn7_7.6.4.38-1+cuda10.1_amd64.deb\u001b[0m\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro  160754004 set 22  2019 \u001b[01;31mlibcudnn7-dev_7.6.4.38-1+cuda10.1_amd64.deb\u001b[0m\r\n",
      "drwxrwxr-x  3 bribeiro bribeiro       4096 mar 20  2019 \u001b[01;34m__MACOSX\u001b[0m/\r\n",
      "drwxrwxr-x 17 bribeiro bribeiro      20480 mar  5  2021 \u001b[01;34mNat19\u001b[0m/\r\n",
      "drwxrwxr-x 21 bribeiro bribeiro       4096 nov 30  2019 \u001b[01;34mNat19_2\u001b[0m/\r\n",
      "-rw-------  1 bribeiro bribeiro          0 set 27  2019 nohup.out\r\n",
      "drwxr-xr-x 40 bribeiro bribeiro       4096 set 23  2018 \u001b[01;34moriginal\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro  881664546 fev 14  2021 \u001b[01;31moriginal_plant_diseases.zip\u001b[0m\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1233422 fev 15  2021 PD_MobileNet_A_L1_1502.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1233359 fev 15  2021 PD_MobileNet_A_L2_1502.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1233366 fev 15  2021 PD_MobileNet_A_L3_1502.csv\r\n",
      "drwxrwxr-x  2 bribeiro bribeiro       4096 fev 15  2021 \u001b[01;34mplant_diseases_data\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro  842382110 fev 13  2021 \u001b[01;31mplant_disease.zip\u001b[0m\r\n",
      "drwxrwxr-x 10 bribeiro bribeiro       4096 fev 17  2021 \u001b[01;34mplantvillage\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1233511 fev 16  2021 plantvillage_1_Ensemble_1602_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1233396 fev 16  2021 plantvillage_1_Ensemble_1602_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1233397 fev 16  2021 plantvillage_1_Ensemble_1602_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1258125 fev 16  2021 plantvillage_2_Ensemble_1602_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1258230 fev 16  2021 plantvillage_2_Ensemble_1602_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1258223 fev 16  2021 plantvillage_2_Ensemble_1602_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1242271 fev 16  2021 plantvillage_3_Ensemble_1602_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1242167 fev 16  2021 plantvillage_3_Ensemble_1602_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1242146 fev 16  2021 plantvillage_3_Ensemble_1602_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1244679 fev 17  2021 plantvillage_4_Ensemble_1602_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1244770 fev 17  2021 plantvillage_4_Ensemble_1602_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro    1244737 fev 17  2021 plantvillage_4_Ensemble_1602_meana36.csv\r\n",
      "drwxrwxr-x  6 bribeiro bribeiro       4096 jun 22  2020 \u001b[01;34msiim_isic_melanoma\u001b[0m/\r\n",
      "drwxrwxr-x 18 bribeiro bribeiro       4096 ago 31  2019 \u001b[01;34mSTFDG\u001b[0m/\r\n",
      "drwxrwxr-x  7 bribeiro bribeiro       4096 fev  9  2021 \u001b[01;34msurrey\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360577 fev  9  2021 surrey_A_Ensemble_0902_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360577 fev  9  2021 surrey_A_Ensemble_0902_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360577 fev  9  2021 surrey_A_Ensemble_0902_meana34.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360577 fev  9  2021 surrey_A_Ensemble_0902_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378678 fev  9  2021 surrey_AVG_Ensemble_0902_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378678 fev  9  2021 surrey_AVG_Ensemble_0902_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400912 fev  9  2021 surrey_B_Ensemble_0902_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400912 fev  9  2021 surrey_B_Ensemble_0902_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400912 fev  9  2021 surrey_B_Ensemble_0902_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385732 fev  9  2021 surrey_C_Ensemble_0902_meana14.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385732 fev  9  2021 surrey_C_Ensemble_0902_meana24.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385732 fev  9  2021 surrey_C_Ensemble_0902_meana25.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385732 fev  9  2021 surrey_C_Ensemble_0902_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378678 fev  9  2021 surrey_D_Ensemble_0902_meana26.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378678 fev  9  2021 surrey_D_Ensemble_0902_meana36.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_EffNetB1_B_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_EffNetB1_C_L1_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378686 fev  9  2021 Surrey_EffNetB1_D_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360585 fev  9  2021 Surrey_InceptionV3_A_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360585 fev  9  2021 Surrey_InceptionV3_A_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360585 fev  9  2021 Surrey_InceptionV3_A_L3_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_InceptionV3_B_L1_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_InceptionV3_B_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_InceptionV3_B_L3_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_InceptionV3_C_L1_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_InceptionV3_C_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_InceptionV3_C_L3_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378686 fev  9  2021 Surrey_InceptionV3_D_L1_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378686 fev  9  2021 Surrey_InceptionV3_D_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     378686 fev  9  2021 Surrey_InceptionV3_D_L3_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360585 fev  9  2021 Surrey_MobileNet_A_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     360585 fev  9  2021 Surrey_MobileNet_A_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_MobileNet_B_L1_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_MobileNet_B_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     400920 fev  9  2021 Surrey_MobileNet_B_L3_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_MobileNet_C_L1_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_MobileNet_C_L2_0902.csv\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro     385740 fev  9  2021 Surrey_MobileNet_C_L3_0902.csv\r\n",
      "drwxrwxr-x  7 bribeiro bribeiro       4096 mar  5  2021 \u001b[01;34msurrey_share\u001b[0m/\r\n",
      "drwxrwxr-x  8 bribeiro bribeiro       4096 ago 28  2020 \u001b[01;34msvhn\u001b[0m/\r\n",
      "drwxrwxr-x 20 bribeiro bribeiro      20480 mar  5  2021 \u001b[01;34msvhn_v2\u001b[0m/\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro         18 mar  5  2021 test1.txt\r\n",
      "-rw-rw-r--  1 bribeiro bribeiro 2054118015 set 27  2019 \u001b[01;31mtest.zip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "313ttIKg8riI",
    "outputId": "32ea2f07-35d7-4504-ce4c-2d7aa40c84bb"
   },
   "outputs": [],
   "source": [
    "# #Images/n02105855-Shetland_sheepdog/n02105855_9415.jpg\n",
    "\n",
    "# import glob\n",
    "# import os\n",
    "\n",
    "# import numpy as np\n",
    "# from matplotlib.image import imread\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # get image parts\n",
    "# def get_image_parts(image_path):\n",
    "#     \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "#     parts = image_path.split(os.path.sep)\n",
    "#     #print(parts)\n",
    "#     filename = parts[2]\n",
    "#     filename_no_ext = filename.split('.')[0]\n",
    "#     classname = parts[1]\n",
    "#     train_or_test = parts[0]\n",
    "    \n",
    "#     return train_or_test, classname, filename_no_ext, filename\n",
    "    \n",
    "    \n",
    "# sample_images = list(glob.glob(os.path.join('train/', '*/*'), recursive=True))\n",
    "# np.random.seed(42)\n",
    "# rand_imgs = np.random.choice(sample_images, size=5*5)\n",
    "# fig, axarr = plt.subplots(5, 5, figsize=(20, 20))\n",
    "\n",
    "# for i, rand_img in enumerate(rand_imgs):\n",
    "#     train_or_test, classname, filename_no_ext, filename = get_image_parts(rand_img)\n",
    "    \n",
    "#     j = i // 5\n",
    "#     k = i % 5\n",
    "#     axarr[j][k].imshow(imread(rand_img))\n",
    "#     axarr[j][k].title.set_text(classname)\n",
    "#     axarr[j][k].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "UOyt3E-j8tJo",
    "outputId": "969c4599-bc6b-46f0-f648-d2cfca0450b0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "#Stop training on val_acc\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "#Save large model using pickle formate instead of h5            \n",
    "class SaveCheckPoint(Callback):\n",
    "    def __init__(self, model, dest_folder):\n",
    "        super(Callback, self).__init__()\n",
    "        self.model = model\n",
    "        self.dest_folder = dest_folder\n",
    "        \n",
    "        #initiate\n",
    "        self.best_val_acc = 0\n",
    "        self.best_val_loss = sys.maxsize #get max value\n",
    "          \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_acc = logs['val_acc']\n",
    "        val_loss = logs['val_loss']\n",
    "\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            \n",
    "            # Save weights in pickle format instead of h5\n",
    "            print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "            weigh= self.model.get_weights()\n",
    "\n",
    "            #now, use pickle to save your model weights, instead of .h5\n",
    "            #for heavy model architectures, .h5 file is unsupported.\n",
    "            fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "            pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "            fpkl.close()\n",
    "            \n",
    "#             model.save('tmp.h5')\n",
    "        elif val_acc == self.best_val_acc:\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss=val_loss\n",
    "                \n",
    "                # Save weights in pickle format instead of h5\n",
    "                print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "                weigh= self.model.get_weights()\n",
    "\n",
    "                #now, use pickle to save your model weights, instead of .h5\n",
    "                #for heavy model architectures, .h5 file is unsupported.\n",
    "                fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "                pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "                fpkl.close()                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUL 1 - Inception - ST\n",
    "\n",
    "from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "# from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, SimpleRNN, LSTM, Flatten, GRU, Reshape\n",
    "\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "# from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def get_adv_model():\n",
    "    f1_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(299,299,3))  \n",
    "    \n",
    "#     #frozen layers    \n",
    "#     for layer in f1_base.layers:\n",
    "#         layer.trainable = False  \n",
    "        \n",
    "    f1_x = f1_base.output\n",
    "    f1_x = GlobalAveragePooling2D()(f1_x)    \n",
    "    \n",
    "#     f1_base = EfficientNetB0(include_top=False, weights='imagenet', \n",
    "#                     input_shape=(299, 299, 3), \n",
    "#                     pooling='avg')\n",
    "#     f1_x = f1_base.output\n",
    "\n",
    "# f1_x = f1_base.layers[-151].output   #layer 5\n",
    "\n",
    "# f1_x = GlobalAveragePooling2D()(f1_x)\n",
    "# f1_x = Flatten()(f1_x)\n",
    "\n",
    "# f1_x = Reshape([1,1280])(f1_x)  \n",
    "# f1_x = SimpleRNN(2048, \n",
    "#             return_sequences=False,                       \n",
    "# #             dropout=0.8                                     \n",
    "#             input_shape=[1,1280])(f1_x)\n",
    "   \n",
    "    #Regularization with noise\n",
    "    f1_x = GaussianNoise(0.1)(f1_x)\n",
    "\n",
    "    f1_x = Dense(1024, activation='relu')(f1_x)\n",
    "    f1_x = Dense(10, activation='softmax')(f1_x)\n",
    "    model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
    "    model_1.summary()\n",
    "    \n",
    "    return model_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1E7n8ds9Mmh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FXZBAIXAElcd",
    "outputId": "0d8aaee3-0db2-4b08-c426-d26e581d2c10"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "19V0B0rIEgso",
    "outputId": "78573b3b-934c-45ae-9c10-ccb28e635e0e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "1JMB1lsREbAE",
    "outputId": "1cad26f1-9c6f-4801-bb78-84f43a11e0c7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "2suPqhuJDOLn",
    "outputId": "d0b80840-ba14-4470-cb33-c850af69491d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "6SqCtLbgSoQ-",
    "outputId": "2a7c1ac8-a9b2-44c2-c368-91125b14a983"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUUPvXA2S7ev"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UsII2atxTYdG",
    "outputId": "a1c0b166-9ed8-4005-faa8-d2932fa8de5a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BL0e6CLIFwxN",
    "outputId": "960af38c-994c-41b2-9f00-a95d1d56ce6c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA1wZ0ODjKlX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7tCxvDxjNU9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgOQh92Ar10r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Dj-itflssqh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwbSVOPnorCq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "cyl_Xjunolpe",
    "outputId": "0ca332e8-f4f4-4903-c7f3-68c5e41ff860"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "zPyjRcTfytFG",
    "outputId": "2de3a5b1-a9f6-4103-fb2b-631c9e505281"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emlc7dUpq9C1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_sKj8LQqr-g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgL7cGRAqy7p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtFSHddZq16W"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGOfqcePBqpH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SjTDA8VC5Ah"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILRxLOABDF7u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "8pDocSJKCtV7",
    "outputId": "a56f8b2d-8684-4f05-e17f-16a84fdd6b3b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WJiLtHmPZ2Ts",
    "outputId": "2e15b430-2dfa-42b8-bc91-6418e714bf62"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "cdFkG0pEacF1",
    "outputId": "6682d252-6c53-4324-a2bf-83d285c6ff27"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41MCKnMGanT1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVSEeQWrbWvn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RM7cE3Skbpw9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "# class CutMixImageDataGenerator():\n",
    "#     def __init__(self, generator1, generator2, img_size, batch_size):\n",
    "#         self.batch_index = 0\n",
    "#         self.samples = generator1.samples\n",
    "#         self.class_indices = generator1.class_indices\n",
    "#         self.generator1 = generator1\n",
    "#         self.generator2 = generator2\n",
    "#         self.img_size = img_size\n",
    "#         self.batch_size = batch_size\n",
    "\n",
    "#     def reset_index(self):  # Ordering Reset (If Shuffle is True, Shuffle Again)\n",
    "#         self.generator1._set_index_array()\n",
    "#         self.generator2._set_index_array()\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.batch_index = 0\n",
    "#         self.generator1.reset()\n",
    "#         self.generator2.reset()\n",
    "#         self.reset_index()\n",
    "\n",
    "#     def get_steps_per_epoch(self):\n",
    "#         quotient, remainder = divmod(self.samples, self.batch_size)\n",
    "#         return (quotient + 1) if remainder else quotient\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         self.get_steps_per_epoch()\n",
    "\n",
    "#     def __next__(self):\n",
    "#         if self.batch_index == 0: self.reset()\n",
    "\n",
    "#         crt_idx = self.batch_index * self.batch_size\n",
    "#         if self.samples > crt_idx + self.batch_size:\n",
    "#             self.batch_index += 1\n",
    "#         else:  # If current index over number of samples\n",
    "#             self.batch_index = 0\n",
    "\n",
    "#         reshape_size = self.batch_size\n",
    "#         last_step_start_idx = (self.get_steps_per_epoch()-1) * self.batch_size\n",
    "#         if crt_idx == last_step_start_idx:\n",
    "#             reshape_size = self.samples - last_step_start_idx\n",
    "            \n",
    "#         X_1, y_1 = self.generator1.next()\n",
    "#         X_2, y_2 = self.generator2.next()\n",
    "        \n",
    "#         cut_ratio = np.random.beta(a=1, b=1, size=reshape_size)\n",
    "#         cut_ratio = np.clip(cut_ratio, 0.2, 0.8)\n",
    "#         label_ratio = cut_ratio.reshape(reshape_size, 1)\n",
    "#         cut_img = X_2\n",
    "\n",
    "#         X = X_1\n",
    "#         for i in range(reshape_size):\n",
    "#             cut_size = int((self.img_size-1) * cut_ratio[i])\n",
    "#             y1 = random.randint(0, (self.img_size-1) - cut_size)\n",
    "#             x1 = random.randint(0, (self.img_size-1) - cut_size)\n",
    "#             y2 = y1 + cut_size\n",
    "#             x2 = x1 + cut_size\n",
    "#             cut_arr = cut_img[i][y1:y2, x1:x2]\n",
    "#             cutmix_img = X_1[i]\n",
    "#             cutmix_img[y1:y2, x1:x2] = cut_arr\n",
    "#             X[i] = cutmix_img\n",
    "            \n",
    "#         # X = seq.augment_images(X)  # Sequential of imgaug\n",
    "#         y = y_1 * (1 - (label_ratio ** 2)) + y_2 * (label_ratio ** 2)\n",
    "#         return X, y\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         while True:\n",
    "#             yield next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "P1hxliT6aR_a",
    "outputId": "a359bc33-6afa-4da1-a5fe-13aab3996ef7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of GPUs: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           10250       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 23,911,210\n",
      "Trainable params: 23,876,778\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    # preprocessing_function=get_cutout_v2(),\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 1\n",
    "batch_size = 32\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('cifar10/cifar10v3/train_resized_299/',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('cifar10/cifar10v3/test_resized_299/',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('cifar10', 'cifar10v3', 'checkpoints', 'Cifar10_Share_4_Inception_ex23_08.hdf5')\n",
    "savedfilename_best = os.path.join('cifar10', 'cifar10v3', 'checkpoints', 'Cifar10_Share_4_Inception_ex23_08_best.hdf5')\n",
    "savedfilename_pre = os.path.join('cifar10', 'cifar10v3', 'checkpoints', 'Cifar10_Share_4_Inception_ex23_08_pre.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_accuracy', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_accuracy', value=0.9900, verbose=1)\n",
    "\n",
    "def rand_scheduler(epoch, lr):\n",
    "    rnd_lr = 10**(random.uniform(np.log10((1e-5)),np.log10((1e-1))))\n",
    "#     if epoch < 30:\n",
    "#         rnd_lr = 1e-2\n",
    "#     else:    \n",
    "#         rnd_lr = 1e-3\n",
    "##     rnd_lr = lr\n",
    "    print('random lr = ', rnd_lr)\n",
    "    return rnd_lr\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-2\n",
    "# decay = lr/epochs\n",
    "# optimizer = Adam(lr=lr, decay=decay)\n",
    "# optimizer = Adam(lr=lr)\n",
    "optimizer = SGD(lr=lr)\n",
    "\n",
    "# train on multiple-gpus\n",
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of GPUs: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    model_mul = get_adv_model()\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    # save initial model\n",
    "    model_mul.save_weights(savedfilename) \n",
    "    model_mul.save_weights(savedfilename_best)\n",
    "    model_mul.save_weights(savedfilename_pre)\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "# result = model_mul.fit_generator(\n",
    "#     generator = train_set, \n",
    "#     steps_per_epoch = step_size_train,\n",
    "#     validation_data = valid_set,\n",
    "#     validation_steps = step_size_valid,\n",
    "#     shuffle=True,\n",
    "#     epochs=epochs,\n",
    "#     callbacks=[checkpointer],\n",
    "# #     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "# #     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "#     verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "d = {'id': [1, 2, 3, 4], 'pbest_value': [0, 0, 0, 0], 'pbest_file':['Cifar10_Share_1_Inception_ex23_08_best.hdf5',\n",
    "                                                        'Cifar10_Share_2_Inception_ex23_08_best.hdf5',\n",
    "                                                        'Cifar10_Share_3_Inception_ex23_08_best.hdf5',\n",
    "                                                        'Cifar10_Share_4_Inception_ex23_08_best.hdf5'], \n",
    "                         'c_value': [0, 0, 0, 0], 'c_file':['Cifar10_Share_1_Inception_ex23_08.hdf5',\n",
    "                                                             'Cifar10_Share_2_Inception_ex23_08.hdf5',\n",
    "                                                             'Cifar10_Share_3_Inception_ex23_08.hdf5',\n",
    "                                                             'Cifar10_Share_4_Inception_ex23_08.hdf5'], \n",
    "                         'pre_value': [0, 0, 0, 0], 'pre_file':['Cifar10_Share_1_Inception_ex23_08_pre.hdf5',\n",
    "                                                             'Cifar10_Share_2_Inception_ex23_08_pre.hdf5',\n",
    "                                                             'Cifar10_Share_3_Inception_ex23_08_pre.hdf5',\n",
    "                                                             'Cifar10_Share_4_Inception_ex23_08_pre.hdf5'],\n",
    "                         'training_flag':[0, 0, 0, 0]\n",
    "    }\n",
    "df = pandas.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join('cifar10', 'cifar10v3', 'data_ex23_08.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = os.path.join('cifar10', 'cifar10v3', 'data_ex23_08.csv')\n",
    "\n",
    "def synch_read_data(data_file=''):\n",
    "    while(True):\n",
    "        try:\n",
    "            df = pandas.read_csv(data_file, index_col=0)  \n",
    "            break                     \n",
    "        except:\n",
    "            #waiting for 10s\n",
    "            print(\"\\n\")\n",
    "            for i in range(10,0,-1):\n",
    "                print(\"re-read the file ....%2d\" %i, end=\"\\r\", flush=True)\n",
    "                time.sleep(1) \n",
    "    return df  \n",
    "\n",
    "def synch_write_data(df,data_file=''):\n",
    "    while(True):\n",
    "        try:\n",
    "            df.to_csv(data_file)  \n",
    "            break                     \n",
    "        except:\n",
    "            #waiting for 10s\n",
    "            print(\"\\n\")\n",
    "            for i in range(10,0,-1):\n",
    "                print(\"re-read the file ....%2d\" %i, end=\"\\r\", flush=True)\n",
    "                time.sleep(1) \n",
    "    return df  \n",
    "\n",
    "def get_pbest_loc(row=0):\n",
    "    df = synch_read_data(data_file)\n",
    "    row=df.loc[row]\n",
    "    pbest_value = row[1]\n",
    "    file_name = row[2]\n",
    "    return pbest_value, file_name\n",
    "\n",
    "def set_pbest_loc(row, pbest_value):\n",
    "    df = synch_read_data(data_file)\n",
    "    df.loc[row, 'pbest_value'] = pbest_value\n",
    "    synch_write_data(df,data_file)\n",
    "    \n",
    "def get_c_loc(row=0):\n",
    "    df = synch_read_data(data_file)\n",
    "    row=df.loc[row]\n",
    "    c_value = row[3]\n",
    "    file_name = row[4]\n",
    "    return c_value, file_name\n",
    "\n",
    "def set_c_loc(row, c_value):\n",
    "    df = synch_read_data(data_file)\n",
    "    df.loc[row, 'c_value'] = c_value\n",
    "    synch_write_data(df,data_file)   \n",
    "\n",
    "#    \n",
    "def get_pre_loc(row=0):\n",
    "    df = synch_read_data(data_file)\n",
    "    row=df.loc[row]\n",
    "    pre_value = row[5]\n",
    "    file_name = row[6]\n",
    "    return pre_value, file_name\n",
    "\n",
    "def set_pre_loc(row, pre_value):\n",
    "    df = synch_read_data(data_file)\n",
    "    df.loc[row, 'pre_value'] = pre_value\n",
    "    synch_write_data(df,data_file)\n",
    "    \n",
    "#training flag\n",
    "def get_training_flag(row=0):\n",
    "    df = synch_read_data(data_file)\n",
    "    row=df.loc[row]\n",
    "    training_flag = row[7]\n",
    "    return training_flag\n",
    "\n",
    "def set_training_flag(row, training_status):\n",
    "    df = synch_read_data(data_file)\n",
    "    df.loc[row, 'training_flag'] = training_status\n",
    "    synch_write_data(df,data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance(w1, w2):\n",
    "    sqr_distance = 0\n",
    "    \n",
    "    w_np_1 = np.array(w1)\n",
    "    w_fl_1 = w_np_1.flatten()\n",
    "    w_np_2 = np.array(w2)\n",
    "    w_fl_2 = w_np_2.flatten()\n",
    "    \n",
    "    for i in range(len(w_np_1)):\n",
    "        x1_fl = w_fl_1[i].flatten()\n",
    "        x2_fl = w_fl_2[i].flatten()\n",
    "\n",
    "        tmp_dis = 0 \n",
    "        for j in range(len(x1_fl)):\n",
    "            tmp_dis = tmp_dis + (x1_fl[j]-x2_fl[j])**2\n",
    "\n",
    "    #     print(tmp_dis)\n",
    "        sqr_distance = sqr_distance + tmp_dis\n",
    "\n",
    "    return sqr_distance**(1/2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open a strategy scope.\n",
    "# with strategy.scope():\n",
    "#     model_mul.load_weights(os.path.join('surrey_share', 'C', 'checkpoints', 'Surrey_4_Share_MobileNet_v2_C.hdf5'))\n",
    "    \n",
    "# model_mul.evaluate(valid_set)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  0\n",
      "WARNING:tensorflow:From <ipython-input-13-9b4709d018ee>:53: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "random lr =  3.921181487646504e-05\n",
      "WARNING:tensorflow:From /home/bribeiro/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 2.3378 - accuracy: 0.1213\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.17220, saving model to cifar10/cifar10v3/checkpoints/Cifar10_Share_4_Inception_ex23_08.hdf5\n",
      "1563/1563 [==============================] - 1070s 684ms/step - loss: 2.3378 - accuracy: 0.1213 - val_loss: 2.2508 - val_accuracy: 0.1722\n",
      "index:  1\n",
      "random lr =  0.09007303023211138\n",
      " 265/1563 [====>.........................] - ETA: 12:34 - loss: 1.3424 - accuracy: 0.5311"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9b4709d018ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#     callbacks=[csv_logger, checkpointer, earlystopping],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m#     callbacks=[tb, csv_logger, checkpointer, earlystopping],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             verbose=1) \n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m#save weights every iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import keras\n",
    "import math\n",
    "\n",
    "#index of this pso\n",
    "pso_index = 3\n",
    "\n",
    "#number of neighbors (max=4)\n",
    "num_neighbors = 4\n",
    "#K coefficient\n",
    "M = 1\n",
    "u = 1\n",
    "\n",
    "tmp_acc = 0\n",
    "tmp_w = []\n",
    "pbest_acc = 0\n",
    "pbest_w = []\n",
    "\n",
    "#accelerator coefficient\n",
    "c1 = 0.5\n",
    "c2 = 0.5\n",
    "# w = 0.5\n",
    "\n",
    "r1 = 0\n",
    "r2 = 0\n",
    "\n",
    "results_stack_accuracy = []\n",
    "results_stack_val_accuracy = []\n",
    "results_stack_loss = []\n",
    "results_stack_val_loss = []\n",
    "\n",
    "warm_up = 10\n",
    "warm_up2_1 = 20\n",
    "warm_up2_2 = 30\n",
    "\n",
    "for index in range(0, epochs): \n",
    "    if ((index < warm_up) or ((index >= warm_up2_1) and (index < warm_up2_2))):\n",
    "        print(\"index: %2d\" %index)\n",
    "    # while gbest_acc < threshold:\n",
    "        #save previous weight\n",
    "        model_mul.save_weights(savedfilename_pre)\n",
    "        result = model_mul.fit_generator(\n",
    "            generator = train_set, \n",
    "            steps_per_epoch = step_size_train,\n",
    "            validation_data = valid_set,\n",
    "            validation_steps = step_size_valid,\n",
    "            shuffle=True,\n",
    "            epochs=1,\n",
    "            callbacks=[checkpointer,tf.keras.callbacks.LearningRateScheduler(rand_scheduler)],\n",
    "        #     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "        #     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "            verbose=1) \n",
    "\n",
    "        #save weights every iteration\n",
    "    #     model_mul.save_weights(savedfilename)   \n",
    "\n",
    "        tmp_acc = result.history.get('val_accuracy')[-1]\n",
    "        tmp_w = model_mul.get_weights()\n",
    "        tmp_lr = result.history.get('lr')[-1]\n",
    "\n",
    "        #save current location\n",
    "        set_c_loc(pso_index,tmp_acc) \n",
    "\n",
    "        if tmp_acc > pbest_acc:\n",
    "            pbest_acc = tmp_acc\n",
    "            pbest_w = tmp_w\n",
    "            #save person best location\n",
    "            set_pbest_loc(pso_index,pbest_acc)  \n",
    "            # save best model\n",
    "            model_mul.save_weights(savedfilename_best) \n",
    "\n",
    "        results_stack_val_accuracy.append(result.history.get('val_accuracy')[-1])\n",
    "        results_stack_accuracy.append(result.history.get('accuracy')[-1])\n",
    "        results_stack_val_loss.append(result.history.get('val_loss')[-1])      \n",
    "        results_stack_loss.append(result.history.get('loss')[-1])\n",
    "    \n",
    "    else:    \n",
    "        # time synchronize\n",
    "        number_of_pso = 4\n",
    "        training_start_flag = 1\n",
    "        training_finish_flag = 0\n",
    "\n",
    "        #set initial training flag to start\n",
    "#       set_training_flag(pso_index, training_start_flag)\n",
    "\n",
    "    #for index in range(warm_up, epochs): \n",
    "    # while i < iter_max:\n",
    "        #start training \n",
    "        set_training_flag(pso_index, training_start_flag)\n",
    "        print(get_training_flag(pso_index))\n",
    "\n",
    "        #save previous weight\n",
    "        model_mul.save_weights(savedfilename_pre) \n",
    "\n",
    "        result = model_mul.fit_generator(\n",
    "            generator = train_set, \n",
    "            steps_per_epoch = step_size_train,\n",
    "            validation_data = valid_set,\n",
    "            validation_steps = step_size_valid,\n",
    "            shuffle=True,\n",
    "            epochs=1,\n",
    "            callbacks=[checkpointer,tf.keras.callbacks.LearningRateScheduler(rand_scheduler)],\n",
    "        #     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "        #     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "            verbose=1) \n",
    "\n",
    "        #save weights every iteration\n",
    "    #     model_mul.save_weights(savedfilename)\n",
    "\n",
    "        tmp_acc = result.history.get('val_accuracy')[-1]\n",
    "        tmp_w = model_mul.get_weights()\n",
    "        tmp_lr = result.history.get('lr')[-1]\n",
    "\n",
    "        #save current location in scoreboard\n",
    "        set_c_loc(pso_index,tmp_acc) \n",
    "\n",
    "        if tmp_acc > pbest_acc:\n",
    "            pbest_acc = tmp_acc\n",
    "            pbest_w = tmp_w\n",
    "            #save person best location\n",
    "            set_pbest_loc(pso_index,pbest_acc)  \n",
    "            # save best model\n",
    "            model_mul.save_weights(savedfilename_best)        \n",
    "\n",
    "        #set training flag to finish\n",
    "        set_training_flag(pso_index, training_finish_flag)  \n",
    "        print(get_training_flag(pso_index))\n",
    "\n",
    "        # check if all PSOs is ready (flag==1)\n",
    "        while(True):\n",
    "            tmp_flag = 0\n",
    "            for flg_i in range(number_of_pso):\n",
    "                print(\"flg_i\", flg_i, \"flag\", get_training_flag(flg_i))\n",
    "                if(get_training_flag(flg_i) == 1):\n",
    "                    tmp_flag = 1\n",
    "            if(tmp_flag==1):\n",
    "                #waiting for 60s\n",
    "                print(\"\\n\")\n",
    "                for i in range(60,0,-1):\n",
    "                    print(\"waiting for ....%2d\" %i, end=\"\\r\", flush=True)\n",
    "                    time.sleep(1)    \n",
    "            else:\n",
    "                print(\"end of waiting\")\n",
    "                break  \n",
    "\n",
    "        r1 = random.uniform(0,1)\n",
    "        r2 = random.uniform(0,1)\n",
    "    #     r3 = random.uniform(0,1)    \n",
    "\n",
    "        #-----------nearest neighbor best--------------\n",
    "        #get neighbor weights\n",
    "        #1\n",
    "        neighbor_c_acc_1, name_file_1 = get_c_loc(0)\n",
    "        neighbor_c_acc_2, name_file_2 = get_c_loc(1)\n",
    "        neighbor_c_acc_3, name_file_3 = get_c_loc(2)\n",
    "        neighbor_c_acc_4, name_file_4 = get_c_loc(3)\n",
    "\n",
    "        #get pre loc\n",
    "        neighbor_pre_acc_1, name_pre_file_1 = get_pre_loc(0)\n",
    "        neighbor_pre_acc_2, name_pre_file_2 = get_pre_loc(1)\n",
    "        neighbor_pre_acc_3, name_pre_file_3 = get_pre_loc(2)\n",
    "        neighbor_pre_acc_4, name_pre_file_4 = get_pre_loc(3)  \n",
    "\n",
    "        #clone model for weights change\n",
    "        model_clone = keras.models.clone_model(model_mul)\n",
    "\n",
    "        model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_file_1))\n",
    "        neighbor_w_1 = model_clone.get_weights() \n",
    "        model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_file_2))\n",
    "        neighbor_w_2 = model_clone.get_weights()\n",
    "        model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_file_3))\n",
    "        neighbor_w_3 = model_clone.get_weights()\n",
    "        model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_file_4))\n",
    "        neighbor_w_4 = model_clone.get_weights()\n",
    "\n",
    "        #clone model pre weights\n",
    "        model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_pre_file_1))\n",
    "        neighbor_pre_w_1 = model_clone.get_weights()     \n",
    "        model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_pre_file_2))\n",
    "        neighbor_pre_w_2 = model_clone.get_weights() \n",
    "        model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_pre_file_3))\n",
    "        neighbor_pre_w_3 = model_clone.get_weights()    \n",
    "        model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_pre_file_4))\n",
    "        neighbor_pre_w_4 = model_clone.get_weights()  \n",
    "\n",
    "        distance_1 = find_distance(neighbor_w_4,neighbor_w_1)\n",
    "        distance_2 = find_distance(neighbor_w_4,neighbor_w_2)\n",
    "        distance_3 = find_distance(neighbor_w_4,neighbor_w_3)\n",
    "\n",
    "        #find the closest neighbor\n",
    "        distances = list()\n",
    "        distances.append((0,distance_1))\n",
    "        distances.append((1,distance_2))\n",
    "        distances.append((2,distance_3))\n",
    "        distances.append((3,0))\n",
    "\n",
    "        print('distances unsorted', distances)\n",
    "\n",
    "        distances.sort(key=lambda tup: tup[1])\n",
    "        print('distances ', distances)\n",
    "\n",
    "        neighbors_idx = list()\n",
    "        for i in range(num_neighbors):\n",
    "            neighbors_idx.append(distances[i][0])        \n",
    "\n",
    "        print('neighbors ids ', neighbors_idx)\n",
    "\n",
    "        #get neighbor bests from the list\n",
    "        neighbor_bests = list()\n",
    "        #remove first element (self distance)\n",
    "    #     neighbors_idx.pop(0)\n",
    "\n",
    "        for i in range(len(neighbors_idx)):\n",
    "            neighbor_best_tmp, name_file_neighbor_best_tmp = get_pbest_loc(neighbors_idx[i])\n",
    "            neighbor_bests.append((neighbors_idx[i],neighbor_best_tmp))\n",
    "            print('neighbor_idx ', neighbors_idx[i])\n",
    "            print('neighbor_best_tmp ', neighbor_best_tmp)\n",
    "\n",
    "        # keep unsorted list of neighbor\n",
    "        neighbor_tmp = deepcopy(neighbor_bests)       \n",
    "\n",
    "        # sort the list for maximum accuracy   \n",
    "        neighbor_bests.sort(key=lambda tup: tup[1], reverse=True)\n",
    "        print('neighbor best ', neighbor_bests)\n",
    "        #\n",
    "        neighbor_best_value, name_file_neighbor_best = get_pbest_loc(neighbor_bests[0][0])\n",
    "        print('name_file_neighbor_best ', name_file_neighbor_best)\n",
    "\n",
    "        model_clone.load_weights(os.path.join('cifar10', 'cifar10v3', 'checkpoints', name_file_neighbor_best))\n",
    "        neighbor_best_w = model_clone.get_weights()  \n",
    "        #---------- end nearest neighbor best ----------\n",
    "\n",
    "        #---------- cucker -----------------------------\n",
    "        particle_w_i = neighbor_w_4\n",
    "        sum_particle_tmp = 0\n",
    "\n",
    "        #remove the fist (self)\n",
    "        neighbor_tmp.pop(0)\n",
    "\n",
    "        for j in range(len(neighbor_tmp)):\n",
    "            if neighbor_tmp[j][0]==0:\n",
    "                particle_w_j = neighbor_w_1\n",
    "                particle_w_pre_j = neighbor_pre_w_1\n",
    "                distance_ij = distance_1\n",
    "                u = 0.2\n",
    "            elif neighbor_tmp[j][0]==1:    \n",
    "                particle_w_j = neighbor_w_2\n",
    "                particle_w_pre_j = neighbor_pre_w_2\n",
    "                distance_ij = distance_2\n",
    "                u = 0.2\n",
    "            elif neighbor_tmp[j][0]==2:    \n",
    "                particle_w_j = neighbor_w_3\n",
    "                particle_w_pre_j = neighbor_pre_w_3\n",
    "                distance_ij = distance_3\n",
    "                u = 0.2\n",
    "\n",
    "            print('u ', u)\n",
    "            print('distance_ij ', distance_ij)\n",
    "            #sum(K/(1+distance)*(particle_w_j-particle_w_i)\n",
    "            sum_particle_tmp -= M*u/(1+distance_ij)*(np.array(particle_w_pre_j)-np.array(particle_w_j)) \n",
    "\n",
    "        #---------- end cucker -------------------------\n",
    "\n",
    "        #update networks' weights\n",
    "        #     w = c1*r1*(np.array(pbest_w)-np.array(tmp_w))+c2*r2*(np.array(gbest_w)-np.array(tmp_w))\n",
    "        #     w = r1*np.array(pbest_w)+r2*np.array(tmp_w)+r3*np.array(gbest_w)\n",
    "        #     w = np.array(tmp_w)+tmp_lr*(c1*r1*(np.array(pbest_w)-np.array(tmp_w))+c2*r2*(np.array(gbest_w)-np.array(tmp_w)))\n",
    "    #     final_weight = np.array(tmp_w)+sum_particle_tmp+c2*r2*(np.array(neighbor_best_w)-np.array(tmp_w))\n",
    "    #     final_weight = np.array(tmp_w)+sum_particle_tmp\n",
    "\n",
    "    #     final_weight = np.array(tmp_w)+c2*r2*(np.array(neighbor_best_w)-np.array(tmp_w))\n",
    "    #     final_weight = np.array(tmp_w)+sum_particle_tmp+c1*r1*(np.array(pbest_w)-np.array(tmp_w))+c2*r2*(np.array(neighbor_best_w)-np.array(tmp_w))\n",
    "        final_weight = np.array(tmp_w)+sum_particle_tmp+c2*r2*(np.array(neighbor_best_w)-np.array(tmp_w))\n",
    "    #     final_weight = np.array(tmp_w)+c2*r2*(np.array(neighbor_best_w)-np.array(tmp_w))\n",
    "    #     final_weight = np.array(tmp_w)+sum_particle_tmp\n",
    "\n",
    "        model_mul.set_weights(final_weight)\n",
    "\n",
    "        print('After ---> epoch=', index, ' r1=',r1, ' r2=',r2, ' current acc=', tmp_acc, ' local best=', pbest_acc, \n",
    "              ' neighbor index=', neighbor_bests[0][0], ' neighbor best=', neighbor_best_value)  \n",
    "\n",
    "        results_stack_val_accuracy.append(result.history.get('val_accuracy')[-1])\n",
    "        results_stack_accuracy.append(result.history.get('accuracy')[-1])\n",
    "        results_stack_val_loss.append(result.history.get('val_loss')[-1])      \n",
    "        results_stack_loss.append(result.history.get('loss')[-1])\n",
    "    \n",
    "#     i = i + 1\n",
    "        \n",
    "print(results_stack_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_stack_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_stack_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_stack_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_stack_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.history.get('val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.history.get('val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.history.get('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=1,\n",
    "#     callbacks=[checkpointer],\n",
    "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen_1 = ImageDataGenerator(\n",
    "    # rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    "    # preprocessing_function=get_random_eraser()\n",
    "    # preprocessing_function=get_cutout_v2()\n",
    ")\n",
    "\n",
    "# train_datagen_2 = ImageDataGenerator(\n",
    "#     # rescale = 1./255,\n",
    "#     rotation_range=30,\n",
    "#     width_shift_range=0.3,\n",
    "#     height_shift_range=0.3,\n",
    "#     shear_range=0.3,\n",
    "#     zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "# #     brightness_range=[0.5, 1.5],##\n",
    "#     channel_shift_range=10,##\n",
    "#     fill_mode='nearest',\n",
    "#     preprocessing_function=preprocess_input,\n",
    "#     # preprocessing_function=get_random_eraser()\n",
    "#     # preprocessing_function=get_cutout_v2()\n",
    "# )\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    # rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 24\n",
    "\n",
    "#\n",
    "train_set_1 = train_datagen_1.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "# #\n",
    "# train_set_2 = train_datagen_2.flow_from_directory('train_resized_299',\n",
    "#                                                  target_size = (299, 299),\n",
    "#                                                  batch_size = batch_size,\n",
    "#                                                  class_mode = 'categorical',\n",
    "#                                                  shuffle=True,\n",
    "#                                                  seed=7,\n",
    "# #                                                  subset=\"training\"\n",
    "#                                               )\n",
    "\n",
    "# # Train Generator (CutMix)\n",
    "# train_set_collage = CutMixImageDataGenerator(\n",
    "#     generator1=train_set_1,\n",
    "#     generator2=train_set_2,\n",
    "#     img_size=299,\n",
    "#     batch_size=batch_size,\n",
    "# )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints','Cifar10_EfficientNetB7_299_STD_tmp.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar10_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar10_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.9900, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "else:\n",
    "    model_mul = model_1\n",
    "    \n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set_1.n/train_set_1.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set_1, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar10_EfficientNetB7_299_STD.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "id": "9it_mwRMLe-e",
    "outputId": "793a2e4b-544c-485f-b030-a2460c523a9b"
   },
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar10_EfficientNetB7_299_STD_L2.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set_1, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar10_EfficientNetB7_299_STD_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar10_EfficientNetB7_299_STD_L3.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set_1, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZBm5kY_TxMv"
   },
   "outputs": [],
   "source": [
    "# #Using multiple models if more than 1 GPU\n",
    "# NUM_GPU = 4\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar10_EfficientNetB7_299_STD_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 40\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar10_EfficientB7_299_STD_2708.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_Eff_B5_345_1511_v1.csv /home/bribeiro/Phong/Nat19/Cifar10_Eff_B5_345_1511_v1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar10_EfficientB7_299_STD_L3.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 72\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "test_datagen_crop = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "testing_set_crop = test_datagen_crop.flow_from_directory('test_resized_345',\n",
    "                                                 target_size = (370, 370),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "#customized generator\n",
    "test_crops = crop_generator(testing_set_crop, 345)\n",
    "\n",
    "step_size_test_crop = ceil(testing_set_crop.n/testing_set_crop.batch_size)\n",
    "\n",
    "tta_steps = 4\n",
    "# predictions = []\n",
    "\n",
    "# import tensorflow as tf\n",
    "# with tf.device('/gpu:0'):\n",
    "for i in range(tta_steps):\n",
    "    print(i)\n",
    "    testing_set_crop.reset()\n",
    "    if NUM_GPU != 1:\n",
    "        preds=model_mul.predict_generator(test_crops, \n",
    "                                           steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "#                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "                                           verbose=1)    \n",
    "#     else:\n",
    "#         preds=model.predict_generator(test_crops, \n",
    "#                                            steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "# #                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "#                                            verbose=1)  \n",
    "#     preds=model_2.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "    predictions.append(preds)\n",
    "\n",
    "mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cifar10_Eff_B5_345_STD_tta_7.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_Eff_B5_345_STD_tta_7.csv /home/bribeiro/Phong/Nat19/Cifar10_Eff_B5_345_STD_tta_7.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar10_Eff_B5_345_L2_TTA3.npy'), mean_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_Eff_B7_299_STD_L3.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Using multiple models if more than 1 GPU\n",
    "# NUM_GPU = 4\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_Eff_B7_299_STD_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 36\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar100_Eff_B0_299_1108_v1.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar100_Eff_B7_299_STD_L3.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar10_efficientnet_B5_345_T2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
